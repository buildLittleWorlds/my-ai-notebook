URL: https://www.youtube.com/watch?v=FIMw04GJJ7U&t=1059s
==============================
Channel Title: ekkol√°pto
Video Title: The Auto-Regression Theory of Cognition Challenges What We Know About Minds | Elan Barenholtz PhD
Publish Date: November 22, 2024
==============================

TRANSCRIPT:

so I I feel like we're living through an inflection point in in human history and everybody knows that um everybody's aware that there's something happening technologically it's also happening culturally um but the the rise of of artificial intelligence is is uh it's everywhere it's ubiquitous um what I think is is not being noticed as much and what to me in some ways is even more interesting is that we're living through uh an inflection point in scientific ific and even philosophical history because we've captured something uh that is so profoundly important to human beings which is the nature of language uh we've learned a whole lot about language uh in a very quick in a very short amount of time such that uh we we have Whiplash and and I don't think anybody's even uh been able to recover themselves long enough to to understand or to contemplate what's happened it's not just that we've created machines that are able to do a lot of the things that only humans have able been able to do it's that in doing so uh we've learned what what the nature of the the the the fabric of thought is and so language makes up uh you know it's the foundation of uh what it means to be a human being it means to be rational what it means to think to philosophize to understand to conduct uh scientific inquiry and what large language models have taught us is that language is is not what we thought uh it was for perhaps all of human history uh probably prior to human history we uh as a species have have considered language to be grounded in the reference the the thing that language refers to and when we talk about the world when we talk about ideas when we talk about Sensations experiences we think that as we're doing so we're somehow making direct contact with the things that the language is supposed to refer to and language definitely is a communicative system and in some sense we know that it maps to the world in a meaningful sense in a meaningful way such that we're able to communicate to one another that there's a door over there you you should go through that door and once you go through that door you'll find uh there's a package on the table and lo and behold if you go through that door you will find a package there's on the table and and language is efficacious it works in this way but language models operate independently of any World Knowledge of the sort that we mean when we talk about these kinds of reference when we talk about the world we language contains within it its ability to generate itself without any grounding in sensory physical knowledge of the sort that we actually tend to think it means so large language models are trained entirely on corpuses of text and in doing so what they learn is the relation between between words they learned this this uh deep kind of statistical although that's not quite the right word mapping between words and the relation to other words and they never have access to any of those reference any of the world uh phenomena the uh the the Numa to use K term the the stuff out there in the world that the words are supposed to refer to and yet language models based on purely syntactic knowledge of the relations between these symbols are able to generate not just any language but the most the mean meaningful language in the very same way that we do and to me that was a very profound shock when I when I actually came to terms with it it it actually Shook and rocked my my world um it I I had to in some ways incorporate the idea that I myself this speaking agent the thing that's talking to you right now doesn't really know what red means it doesn't know what a chair is doesn't understand that there's an external physical Universe at all uh it knows how to speak about it and knows how to communicate about it and it is able to couple somehow and this is something that uh I think will will uh this is this is what the field of linguistics the the future field of linguistics is going to have to and not just Linguistics but all of all Neuroscience all of psychology is going to have to sort out is how does this mapping work of course the language ultimately communicates and maps to the world but it doesn't contain within it any knowledge of sensory phenomena of any of the experiential aspects that we as as uh living breathing biological agents mean when we talk about the physical world so the idea that language is this modular system that can operate independent of these sort of sensory phenomena to me changes everything about honestly what it means to be a human being certainly what it means to think and to talk about anything and the implications are so profound that it's almost impossible to to contemplate and I don't think that people are taking this seriously I don't think that most people have come to terms with us or even realize this and I'm talking about not uh just regular individuals who or may not be aware of how large language models work um or don't understand the technical details I'm talking about people who are deeply steeped in the field who are fully aware uh that the language models operate independently of any any uh experiential or or sensory information but haven't really grasp what that means so what does it mean um well at the very least uh it means that the informational system that we call language is in some ways divorced from the experiential and so when we think about the mind and when we think about experience when we think about qualities qualia uh what it feels like to see the color red we may be thinking in language but the language doesn't actually have the ability to make contact with the phenomenology so we have a word red and I can use that word and when I when I use it it might engender Within Myself an experience of red and it might do the same to you as I say imagine a red patch you can do that and your visual system will generate the experience of redness and it'll be very similar we we know this from brain Imaging very similar to the kind of U neural patterns that you have if you were actually seeing a red object so you'll experience red as you say the word red but the symbolic system that is generating that word red and the meaning of the word red within that symbolic system doesn't actually contain within it the experiential aspect my personal opinion is that this is actually the core uh the the the the core basis of the Mind what's the so-called Mind Body problem the reason why humans for for perhaps all of history um and up to the current time sense that there's a deep dichotomy between the mind and the body is it because there is uh the mind that we're referring to our in that case is the objective mind the mind that lives in the world of symbols the world of language that's trying to ration understand and contemplate the universe from the symbolic perspective whereas the the mind of experience is really the mind of the body the thing that sees is not the thing that speaks the thing that sees and experiences is not the thing that has access to the symbolic forms that do the communication and so there is actually a huge gap there's a computational gap between the linguistic system and the experiential system the sensory experiential system and so I think that this is actually finally in some ways a deeper insight into the foundation of this core philosophical problem that has been you know sort of the source of of well all kinds of speculation uh all kinds of of philosophical philosophical Jiu-Jitsu uh trying to to to fold language into somehow uh a form that it's not really meant to take because language isn't capable of grasping what it is to feel and therefore it's inherently fundamentally incapable of talking about the experience as is they Liv the felt experience so I think this is an interesting this really just one example frankly of one of the profound implications that come from understanding the true nature of language there are many others obviously in fact it's as I think I mentioned it's the the potential the ramifications of understanding language as being a self-contained autogena of system uh go beyond uh anything that we can call sort of the the temp uh the way the way that that problems have been conceptualized up now have been conceptualized incorrectly because they've been conceptualized linguistically and we didn't know what language was to begin with such that we could really understand and look from the outside at how these these problems have been conceptualized so the problems of philosophy themselves have all been conceptualized linguistically if we have a different conception of what language is then that changes what these questions are in the first place and so in some ways all the philosophy has to be redone and when I say philosophy I don't just mean academic philosophy I mean at the deepest level what we mean to know what we mean to understand and those those are of course words in and of themselves we have a very vague intuition about what they mean but now at the very least we can say well understanding and knowledge are primarily or fundamentally linguistic conceptions and by virtue of our very recent understanding of what language is that is going to change and should change everything we we thought we knew about the problems themselves and so it sort of wraps around on itself uh in in a kind of G girdle kind of fashion where language is trying to understand itself when we philosophize we're doing so in language and we're in in in the process of doing so it's it's language grappling with language at the same time language is also in some mysterious way trying to Grapple with extra linguistic phenomena like for example the Mind Body problem where you experience and I have a word called experience and somehow that seems to this unified self to refer to this thing that's outside of language and so this in some ways perhaps helps to solve certain kind of philosophical problems but it also opens up a pendor box of potentially new problems problems such as how can language refer when it's inherently autogena when everything that language needs in order to produce itself is contained within it only the relationship between these symbols how does language refer how does language both externally from a communicative standpoint work and then how is it that I'm able to listen to myself talk refer to things seemly refer to non-linguistic aspects of my experience and then at the same time I know and my lingu and when I say I I mean the linguistic me how is it that the linguistic me is talking about this Paradox so the Paradox is abound they they kind of uh they start to multiply in some ways but at the same time I really do believe fundamentally that we have a novel Insight something that humans have never had as to the nature of what language is how it operates and this really does this gives us a a uh a perspective a a a kind of a microscope a lens unto the nature of our minds and then by virtue of our minds our mind's conceptions of reality that we didn't have before so it's an incredible extraordinary time to be thinking about the hardest problems the most uh basic problems the most fundamental challenges of philosophical challenge intellectual challenge that we've ever had um it's it's time to start writing a new book in some ways about what it means to be a human being and at the same time there's something deeply disturbing about all this it seems almost like there's dichotomy there's there's there's a different informational system that's operating in in each one of us at any given moment that isn't really us and sometimes makes me uncomfortable when I think about it that the thing doing the talking isn't the thing doing the feeling seems almost like an outof Body Experience I'm listening to myself talk right now who's actually forming these words they're coming from somewhere it feels like me but the me that feels the the warmth of the sun on my face and that feels the pressure of the of this chair on my body isn't the same me that is actually talking about it and that is a an uncomfortable realization and if we go a little bit further we have to wonder where did language Truly Come From it's a social phenomenon language is inherently communicative it lives really not in any individual mind mind but it lives in the collective mind of people who use that language and in some sense what that means to me is that whatever that system is whatever that informational organism that's doing the talking doesn't really live in my body or certainly not my body alone my feelings are my own the the the experiences I have the subjective qualitative experiences are very much my own my own bodily experiences but ideas Concepts all of these things that are the lifeblood of language they don't actually belong to my brain they don't belong to my body they belong to some collective system some informational system that a is larger than me in some ways lives outside of me is far beyond my understanding as a living feeling individual and once again this is an uncomfortable thought it it it almost feels you know almost parasitic that there's another organism and it's not me that's living inside of me and this is the kind of stuff I think about all the time now and so I think it's it's a fascinating and and bewildering uh time to to be a human being if you if you contemplate these things these are thoughts that no human beings really have ever had before and people have struggled certainly with the nature of language and and I'm sure that similar ideas have been expressed as conjectures that language in in some ways is a distinct informational system but now we know it's true in a deeper way than I think we ever really could have because we know that large language models we know that the autogenous systems operate independently of any physical form of any embodiment and so to me this is something that changes my my perspective on the of myself and culture and knowledge and humans human beings place in the universe and it also makes me wonder what language really really is uh where did it come from how does it subsist across individuals in it Collective way such that it both operates within an individual makes sense to an individual allows us to communicate as individuals but also seems to have this really distributed Collective life all of its own besides these uh sort of deep philosophical meanderings I think there are some really important uh and also foundational lessons that we're learning from the language models that actually transcend language it's not all about language and that's that there's something very uh special about the way large language models solve the language problem that tells us first of all about first first and foremost about language but my conjecture is that it has implications Beyond language so the the way the large language models Works they you've got a train Network and with the train Network recz is is in any single past takes in an input it's a sequence sequence of tokenized words and then does the next token prediction So based on previous sequence of words what's the next word and then this the model the the train Network simply does that it just says based on the previous sequence here's what the next word should be now some people call that prediction I think that's not a good word for it and I might get into why I think that's an not an app term but at the very base let's just say computationally that's what they're trained to do here's a large Corpus you've learned from that Corpus that given a certain sequence you should produce another a different uh token now the magic of of the language models is not in that inferential process itself but in the autoaggressive nature of it so autoaggression basically means that once the model has produced uh its output it's produced uh the next token that token then joins the sequence that serves as the next input and what language models do is by producing that next token they've now created an input for themselves to then be able to produce the next token and that's the at the core Foundation of what large language model gives langu large language models durability is that there's this the context um it's the the information that's in the prompt and the prompt can be a few words it can be paragraphs or it can be in larger an entire book's worth of of text and then produce that next token and in guessing that next token or by uh producing that and producing that next token they then are producing the context the they now and plus one context that allows them to generate the next token and this is what they're trained to do uh they're trained to produce that next token but that allows them in the in the uh framework of say uh you know an actual chat uh environment to produce sequence sequences of language and that means that this utter aggressive uh feature is actually what the modelss have learned to do it's not that they've learned to produce just next token but they've learned to produce the next token such that it's going to serve as the basis for the next token now if we take that a little further what that what that implies is that human language on which all of the Corpus that all these models are trained on is the Corpus of generated human language human language itself has this regressive process uh built into it that the statistics the relational uh properties amongst words in the Corpus is such that it's meant to be able to do this next joken Generation Auto aggressively and so I believe that language the and the structure of language is designed in such a way that it's meant to be generated autor regressively that the map that's contained within language is has its its properties such that auto regressive generation is possible now once we say that uh we can then the implication is that human Minds which are the basis and and the goal uh by which the structure of language has been designed human minds are themselves autoaggressive and I believe and this is certainly a conjecture at this point but I believe that this is not just about language at all that language uh wherever it came from however it developed took advantage of the fact that brains actually operate autor regressively more generally so what I mean by that is that not just linguistic but not just linguistic cognition but all of cognition is probably autoaggressive in the same sense but what would that mean well what it means is that our neurons uh form patterns of activation and those patterns of activation can serve through various sort feedback loops and and residual activation serve as the basis for the next Activation so what we are cognitively speaking what what what brains are doing computationally is performing this kind of autor regressive generation the pattern at any given moment is the product the the P the pattern that's generated in given moment is the product of previous patterns and I don't know how far far back it goes um but not just the current state it's not a marvian system it's not that the state determines the state but it's various previous states determine the upcoming State and so when we talk about thinking and we talk about cognition the kind that takes time when we have to think through a problem either linguistically or visually or for auditory when we think about about a tune when we think about mapping out a uh let's say we need to get from point A to point B or we think about uh mapping out our schedule for the next day or week and we're thinking sequentially we're actually engaging in the same kind of autor regressive process and the reason why this kind of thinking takes time um I'm rinded of of Dan conman's uh Thinking Fast and Slow the reason why thinking takes time is because it's not a single pass it's not an inferential feed forward single pass here's what we know uh already and here's what we are able to determine based on that knowledge here's the state of the environment and here's the decision that we make based on the state of the environment instead what we're doing is we've got some sequence of patterns based on our previous experience and then we generate the next pattern but that next pattern isn't the decision it isn't the thought it's simply the next pattern in the sequence quence that we're going to continue over time and so when we're thinking things through uh when we're thinking in general I think what we're doing is we're engaging this autoaggressive processing and I I'm again it's a conjecture but I think that this is going to provide a completely different framework of thinking about what neurons and the patterns across neurons are really doing neurons are optimized not to produ something like prediction um or to produce an output but rather neurons are generating the next pattern in the autor regressive sequence such that it will be able to produce the next pattern ultimately of course this is functional the next pattern is not just any pattern it's just like large language models when they produce the next word if we train large language models on a random arbitrary map of words they could learn what would be the the next uh token based on any arbitrary mapping but the arbitrary mapping isn't arbitrary the mapping is not arbitrary the next word in a for a large language model is functionally accurate it's not a prediction uh of what the next word should be it's actually the model's best approximation of what the next word should be in order to finish the thought that was uh based on the sequence that came before and so it has utility it's functional when when when language models produce the next token they're doing so in such a way that it's expressing something meaningful similarly in regards to General uh cognitive processes I think they're Auto regressive in the same sense we produce a pattern the the this the previous sequence of patterns produces a next pattern that will have some functional purpose that pattern could be one that generates ultimately a some sort of Behavioral response or it could be a pattern that just produces the next piece in some sort of thought process but neurons and the patterns they generate are going to be optimized for this kind of Auto regressive generation and that's a completely fundamentally different way of thinking about what neurons are doing in addition when we think about the passage of time and how the autoaggressive process works in actual brains what we know that we don't have perfect uh it's perfect preservation of information uh over time so the the the words that I just spoke you know a few seconds ago are in some ways act still active in my brain and we see this actually from you know long-standing psychological experiments short-term memory for example the way we test short-term memory so-called short-term memory is we ask people to repeat something that was just spoken and we're able to do this uh because there's preserved activation which serves as the context window for the Next Generation But as time passes I can't actually recite to you any of the words that I spoke five six sentences ago and yet those words are still guiding my current generation so the context window in the case of cognition let's just talk about language generation clearly exceeds that which we can access directly and explicitly I can't actually recite to you those words from the beginning of this conversation but at the same time they're clearly part of the context because they're guiding the generation so something's happening to information uh it's preserved in some form but at the same time it's not no longer necessarily fully accessible my personal view is that the accessibility that we even have the ability for example to recite the last few words that I said right so you can do this you The Listener right now can recite some of the words I just said um but you can't go back further the ability to recite even those words that we recently do that we most recently uh recited is some is called refer to a short-term memory and it has a certain duration sometimes they about 15 seconds uh maybe seven plus or minus two uh chunks as they're sometimes called that's what we observe when we do experimentally we ask people to recite the information however my view is that shter memory isn't actually functionally designed to be able to retrieve the information instead that's simply how we're able to detect that it exists to do these weird kind of experiments and ask people to recite stuff yes people can do that but that's not actually the function of those activations I believe that the reason we're able to do that is because we're piggybacking off of this residual activation that's necessary in order to produce the next token so we have this context window doesn't consist simply of the last moment the last word or the last micro you know chunk of of time instead it goes further back it has to still be in there it's somewhere in our brain it must be because otherwise we wouldn't have able to do the autoaggression appropriately so the fact that we can measure that that people can recall this information the fact that people can retrieve that I think it's an epy phenomenon it's it's it's just there by virtue of needing that continuous activation for the purpos of aggression but we happen to be able to also because it's still there we can go and retrieve that information and this radically changes the the core model this the modal model of memory which has sensory memory short-term memory I I'm convinced that sensory memory and short memory are not actually memory stores in the traditional sense at all their purpose is not to be able to retrieve that information in the form that it's in and in the form that the experiments require rather what we're doing by performing those experiments is measuring this residual activation and that means what we've got from these experiments and I'm thankful for them uh is act an actual clue that this residual activation persists at the same time I think some 5050 60 years of cognitive psychology has gotten fundamentally wrong that these are not memory stores in the sense of the uh encoding storage and retrieval purpose that the the we don't maintain uh the last few words or sentences so that we can then bring them to back or manipulate them um and do something with them in that in that form instead they are residual activation that allows us to continue the auto autoagressive generative process same same holds by the way for sensory memory and sensory memory I think is is an even more obvious case I've never heard a good account as what what sensory memory is really for sensory memory is this highly High Fidelity uh very very rich um uh from from the standpoint of um the the amount of information is is supposed to that we can retain for about a second is there's very high fidelity uh memory store supposed memory store um that careful experimentation has has uh has been able to uncover people can remember a letter Grid or a number grid um with very high fidelity for a brief amount of time if you query them right away after you've shown it supposedly this is a form of again memory in the traditional sense where it's supposed to be able to encode information store it so that we're able to retrieve it but the Isis isn't really a good account for why you'd want to hold High Fidelity information for a few milliseconds U because what are you going to do with that behaviorally speaking it doesn't seem to have behavioral much of a a behavioral function according to my perspective it's it's very un very easy to understand it it's just the residual activation which is either transformed or decays over time but the purpose of it is not retrieval the purpose of it is in order to generate the next token and when I say token I mean the next neural pattern that's necessary for the continuation of the autor regressive process and so we do we can do this linguistically but we can also do it visually fact that you can close your eyes and and have an image of the world that you just saw uh for a brief moment and and then that quickly decays isn't so that you can then think about in that brief few milliseconds think about what you just saw instead it's simply our ability for one reason or another we have this ability to interp and to observe something about this residual activation and so the residual activation is there not for the purposes of retrieving but for the purposes of autog generative generation