URL: https://www.youtube.com/watch?v=YBNq_9QeSvA&t=353s
==============================
Channel Title: Elan Barenholtz, PhD
Video Title: Our Conception of Working Memory is Wrong? | Professor Elan Barenholtz
Publish Date: June 11, 2025
==============================

TRANSCRIPT:

Hey everybody, uh it's Elon Baron Holtz. I'm a professor at Florida Atlantic University and I'm working on uh generative theory of cognition in the brain and it's all based on large language models, the things that underly chat GPT. And the core idea is that the the basic math uh of how these things run isn't just a metaphor for thinking about the mind and the brain, but it is actually the fundamental core algorithm that is what our brain is running. So it's not even about explaining the brain. It's about what is the hardware of the brain? What's the software? what's the algorithm that it's instantiating and what I want to talk about today is this this idea of uh complexity which riddles the core enterprise of uh building machines that can do smart stuff and it's been uh it's an intricate and complex mathematical field that tries to capture what computing systems are and aren't going to be able to do uh and in and in what time. And the notion the the framework uh the computational framework is based on some something like a touring machine. And what I think we've learned in the last uh couple of years is that we can definitively say that that's not how the brain works. And then the the question then becomes okay well what lessons from computationalism uh actually may have relevance to thinking about cognition. So, I'm obviously going out on a on a in some ways on a theoretical limb, but I don't think it's I think it's a very firm limb. I don't think it's going to snap by saying that human cognition, at least linguistically expressed cognition like what I'm doing right now, all philosophy, science, ultimately math, math is going to be uh a tool used by this linguistic system. Um, but all of it is going to be folded into a an auto reggressive u model similar to what large language models do. And if that's the case, then the kinds of questions we were interested in asking in relation to comput computational systems are still going to be relevant, but only in regards to symbolic sort of classical computational systems. In other words, the computers that we have and the way they operate and they run is still going to be an area for complexity theory to to operate. question in my mind is okay are there lessons learned there that could potentially fold over to the human mindbrain and I think at certainly at at a high level there are commonalities but then there there are very distinct differences and maybe those are what are most interesting in some ways and about thinking about this contrast is that the the brain doesn't break uh the brain is not a computation ational system in that what happens at time step um you know t + 10 isn't necessary for doing time step t+1 and therefore there isn't this contingency brick in this brittleleness that's inherent to sort of symbolic computing where you have to get to the end of the argument uh to find out what the argument was such that you can now say what am I supposed to do with this input The auto reagent model says there's one rule, one update rule and that is next token and there's no contingencies built in and that means it's an extremely simple computational algorithm. Uh first of all uh it's it's it's simple in in the sense first of all you can write it down very simply. um uh but that of course you know comagor of complexity or something uh what you've got here is is is probably easy in some ways to instantiate in hardware because of its inherent simplicity. Um but I think even more deep than the simplicity is this unbreakability. So you know computer programs hang and and they and they loop um and that's because of this inherent brittleleness of this this this contingency this dependencies uh that uh it goes beyond just next token. But if you can solve things with next token that means you can't f up the system too hard. Uh because what can happen is like a stream running down water. It's going to hit a rock. It's just going to go around it. And then it's that's what the stream does and it's computing that. And so what you throw at it and that's you know all the context whatever is going on in our uh sort of computational environment that goes into our input is what shape the stream is going to take. But that's called computing. And there's no such thing as the stream saying wait I wasn't supposed to do that go back up and start over. Um no the stream runs. Now in the case of cognition uh in the case of of human cognition of course you got to think about functionality. It's got to run and do something. The stream is computing something of course and it's not just defined within the stream. You can build uh an autogressive system that that spits out your nonsense. Well I mean of course take any untrained transformer and it will do something. Uh, and it it is auto reggressive and it's doing the computation so to speak it's supposed to do. But that's like a stream that's and maybe the metaphor is going to break down real fast, but you know stream that's just going off in all different directions and isn't sort of actually computing a shape of a trajectory which is you know we can think of it as a stream as doing. Um, we want we want our autogressive computation to do things and and it does do things. uh and and of course that's the essential question is how do you build something that does stuff and not just language by the way but maybe other stuff too in this failsafe way um I think that's that's the question the new question in some I think um of of psychology of neuroscience of I I would say even philosophy um whatever this amalgam is that's trying to figure out the nature of thought and and computation And is it how does such a system that's just doing next token mind you've got uh you know the residual you got the context it's it's and you and you can represent that in very rich ways um but you're still doing this kind of next token how do you how do you get utility out of that the kind of utility that we know we have um this is this is what the the new science the new field has to has to do has to figure out um how do you build things out of that um but I think it's a very key poor insight um that there's an anti-brittleleness inherent in this kind of building system this way. And so this is what evolution, nature, uh information itself, computation itself sort of converged on as being the solution. One of the deeply challenging outcomes of of thinking of the the mind utter aggressively is it really kind of destroys this this no the the common sense notion of of a memory and it's so deeply entrenched in us when I think you know what is what does your mother look like um what did you do last summer we qualitatively have this experience of we we're calling something and somebody brings it to us and it shows up in our mind but it's it's already there. The image of your mother um or some sort of video of you know splashing through the waves. These are recalled and we sit and watch them like sort of passively. But that's not what's actually happening. What's happening is we have this as I we have this capability this we have this engine that's able in the moment to generate that image of your mother on command with you know the the appropriate input you say hey visual imagery system give me an image of my mom and it generates it in that moment but that image doesn't exist anywhere in the system it's not there. It's not in your brain. Even if I could completely decode your brain, unless I was able to run it with that input, the image isn't really there. And so memories in some ways aren't real. They're not uh the things that we kind of intuitively feel that they are, but at the same time, they're very real in the sense that we can generate them on on demand. Sometimes these are memories that we cherish. uh these are things that we want to be able to pull out of our our kind of mental time capsule and look at it again. And the idea isn't that your your mom's face is forever lost um and it isn't really there. It's an illusion. It's that the ability to generate that is what it means to remember what your mom's facing. Now you can picture your mother uh not just in, you know, a single uh kind of front facing uh but picture from the side, picture her uh making your breakfast as a little kid. You can do whatever you want with this because it has this this kind of endless potentiation. But this kind of raises the question, okay, thinking about it this way, thinking about memory this way, what if there are what if there are memories that I want to be able to generate later? Uh, or a better way to put it, it's not a memory I want to be able to generate, but what if what if I want to have certain kind of generative abilities later on? Instead of thinking of it as how do I store something now that I can later retrieve, it's how can I ensure that I'm going to be able to pull it up on demand later on. And so let's say there's something that's really important to you, really precious, really valuable to remember. Is there a way to encode that so that you have a high probability of being able to be able to later generate it? Now, of course, we we know that there's a vast literature on this. It's there's a there is a substantive empirical scientifically uh established literature on how to encode information such that you can later remember. It's it's the basically the entire field of of learning. Uh how do we learn information such that we're later better later able to retrieve it? But the characterization, thinking about how information actually is encoded and then later used has almost certainly dramatically influenced the way that this field evolved. So many of its findings of course are going to be valid. If if you learn better under some circumstance or the other and we can measure that in later job performance, later academic performance, that's real. I'm not suggesting that uh all of the tools that have been designed are no longer valid. But what I am suggesting is that there may be other kinds of tools, other kinds of frameworks that are sitting right in front of us that may be obvious if we think about memory in this other way. If we think as a degenerative process rather than as an retrieval process. So that's something I think I'd also like to explore going forward in a research framework. And what does that look like? uh what does it mean to to think of qu of memory uh not as a as a storage retrieval process but as a generative process? How does that change how we educate as does how does it change how we ourselves uh come into contact with and and digest and process information um and feed it to ourselves and maybe also how do what can we do in our minds uh what sort of cognitive uh kind of frameworks that we can actually induce uh autonomously autonomically or internally might be available to us. Thinking about processes this way because it's a much more dynamic thing. If you're thinking about how do we just store information well? We can dress up the information in certain ways. We can package it. We can organize it. Um that means once it gets in there, you're done. And you know, hopefully you'll remember it later on. But if in fact what we're talking about is a a much more continuous generative process then there may be far more actual tools and points of intervention at our disposal uh than thinking about it simply in terms of cold storage and retrieval. So there's this big question why why does math why is math so effective in making predictions and and physics and why in general? Uh well, physics is really just a a mathematization of physical observations, predictions. And why is it so unreasonably good? And I think the thing we're kind of missing is that math and all the derivative kind of subjects that that uh extend from it is a human artifact that is couched in based on sort of the same what appear to be the same core principles. uh as language. Uh, of course, it is itself math or language. It's it's it's saying we're gonna what it's doing is self-consciously doing symbolic representation. But where did we get the idea of symbolic representation? Well, of course, we got it from language. You know, that's a cat over there. Oh, there's this thing. We could write it down. We can say it and it picks out an object there. And then we can string these things together to have some representation of the world. And you know math of course borrowed this idea from the observation from natural language that you could res represent things like you know numbers using certain kinds of symbols and then if you string them together in a certain way and then run certain kind of operations on them the the thing it picks back out is going to be some fact about the world as well. abstract mathematics. and ends up not worrying about any sort of uh actual natural kind physical representation that the that the numbers uh represent necessarily that the symbols are are can just be abstract entities in their own right but the whole idea of symbolization playing around with symbols of course is borrowed from language but I think the unreasonable uh utility of it is because it's actually derivative of the the much greater power of natural language. Well, let's let's start actually let's let's try to dissolve this kind of divide between long-term and working memory and thinking about these as distinct systems because I don't think that's how it works. I think we now have a very good model of of how it works and it doesn't actually subscribe to this this this core notion about what memory is and what it's doing and therefore this this divide and then let's think about what the implications might be in relation to what we're actually trying to do because parathetically I'll say that our notion of memory is very deeply tied up in, believe it or not, even if if you've never thought about it before, in a sort of a computational framework. The idea that we're storing a bunch of stuff for later and then where we're going to go again, we're going to pull that stuff out and remember it. And I think that could have very broad implications for thinking about what it would mean to enhance, let's not even call it memory, enhance our performance. What do we really want? We really want in the moment to do the right thing to to operational thing. And if that requires retrieving information as we would typically think of it, we want that to work. We don't really care if if and when and how it's stored. What we really care about is runtime. We want to be able to do the thing that we tend to think memory supports, right? We want to be able to generate meaningful responses to questions. Some of those questions require certain past information making its way into the current moment. And at that level of generality, uh, everybody wants to enhance their capabilities. But if you think about it from the wrong standpoint, you might not be thinking about how to do that enhancement correctly either. Because if what you're thinking of is like how do we appropriately store facts, store information, and then later on have the right tools to get that information back. Well, that's going to come with certain kind of regimens, certain ways of thinking about how to solve the problem of enhancing the leader performance. My argument is that that's fundamentally that's just actually the wrong model. It's the wrong model for thinking about what the actual process of generating the behaviors we want. Like like when when I'm talking to you now and I'm talking about large language models and I'm talking about memory and enhancement and all of that in some ways I'm obviously using information from the past, right? that information is well this is what we're talking about is the conversation and and I know what a large language model is because I read about it um and I program them and it's certainly true that that information is coming through in what I'm saying right now but that doesn't mean that we have to think about it in terms of storing information in this in this static form we want to produce the behavior we have a model now that produced the behavior that doesn't store information in this way. It does and when and at runtime it's not retrieving anything. So what are the implications if instead of thinking about runtime performance as storage and retrieval but just thinking about the performance itself and thinking about that there's this stream of activity that's happening cognitively. We can think of it as computational level. We think at the mental level it may have some overlap even with sort of conscious thought but that's for a later conversation but the process is one that we can model in terms of influence rather than memory. Past events, things that have happened in your long-distant past, things that have happened in your current p in your more recent past are influencing your current current generation. Can we call that memory? Well, sure, in the sense that the system changes in the past and that affects its performance later on. But is information stored in the traditional sense? No. Because in a large language model, in an artificial neural network, what you've got is just changes in these parameters, changes in the structure, if you want to think about it that way, of the network. And those changes aren't actually representing some specific set of facts at all. What they represent is given a current input right now, what are you going to do about it? And that input could be what is this? What is the conversation we're having right now? Well, it's a conversation maybe about large language models and autogression as a model. Okay. Um what's the core thesis? And I could answer that question. Um what's uh uh the the 10th word that I said um you know when I started the conversation? I can't answer that question, but that's yet another thing I can do with this information. Right? In other words, what's happened in my recent past has an infinitude of possible outcomes. And so, we can't think in terms of a single uh static fact that's going to somehow end up coming out of my mouth. Instead, like a neural network, we're changing things such that we have now a completely different trajectory uh of how the system is going to go. So from a metaphor standpoint, instead of thinking of sort as a computer program or storage retrieval process, the the metaphor that keeps coming to my mind is sort of a stream that's running and it's doing stuff along the way, useful stuff. Um, but if something interacts with that stream, it's going to change the shape that it takes and it's going to do so with something like what we'd call memory. Um, but it's it's that the information sort of it sticks around. It's it sticks around in the system. Like the the previous the previous words I said for example are influencing what I'm about to say and they're still doing it now. Right? The words I just said, you know, 10 words ago, now it's 15 words ago, now it's 20 words ago are influencing what I'm going to say. That's that's what working memory is in my view. It's not that there's information that we're going and retrieving. It's that the the past history and is it's non Marovian the past history is continuing to have an influence on on what I'm doing now. And so from a standpoint of sort of enhancement and thinking about how we can improve uh runtime performance. What this means is we have to think in terms of how do we nudge the system? How do we move the system in a direction that gets us where we want to go? How do we how do we set up sort of the the preconditions or we shouldn't even call them preconditions. It happens in real time. What can we do to the stream such that it takes the shape a more optimal shape. And this is a very different question than thinking about how do we store certain kinds of information with fidelity uh so that you can later retrieve them accurately. It's how do we encourage the right kind of influence? And so I don't have a clear idea as to how you actually do this kind of manipulation, but I think a paradigm shift could lead to completely different ways of thinking about these kinds of tools. what what thought tools might exist uh already or what's at our disposal that can help us shape that kind of ongoing process. What how can we experiment with that? How can we introduce information somewhere on the stream? Where should it be? uh you know is it a minute in that we should introduce some concept that would end up showing up in later uh thought stream to and we don't want it to be one specific concept of course but given a particular task ahead of uh let's say you're you're trying to get somebody to you're teach you given them some instructions and you later on to produce and and and and uh be able to carry out some task or explain what it is you told them right these are some very basic sort of memory based tasks What can we do along the way to potentially influence the outcome is being in the direction you want? What would enhance quote unquote understanding? What would that mean? Well, it would we could show that this means that somebody's able to produce the task later on more efficiently, maybe more dynamically, maybe more flexibly, so that if something comes along, it doesn't throw them off. the stream is able to bypass it in a in a more effective way. What do these tools look like? What could they possibly be? How could we experiment on them? So, I think these are new kinds of questions that we can contemplate now hopefully use some of the existing tools we have in say in the even in the meditation uh or in um you know just basic mind training uh whatever even your traditional uh educational toolkit. How can we take these tools but now use them for actually a radically different task? Uh so that's that's I think something I'm very interested in exploring and understanding and and experimenting with. And the the cool thing is we can do these experiments cheap. Uh we can kind of run classic experiments. They would not be by the way short-term retrieval memory kind of experiments cuz those are stupid. Um because what you ask people to do is to explicitly retrieve what happened in the past. And the whole point of my theory is that that's not actually what we do. uh we're influenced by the previous pass. We don't go and retrieve it. The reason why people studied that was because they were kind of looking where the light is and it's a very it's a simple thing you can measure. But it's it's not a particularly useful thing to measure and it's not a particularly useful thing for people to do. What we really want from memory is to be functional. What we want from memory is to do the right thing in this circumstance. uh in 99.999% of cases that's not to explicitly recall and retrieve information from the recent past in some form. It's to be influenced by it. It's I'm going the things I'm going to say now in this part of the sentence are meaningful and smart because of the beginning of my sentence. And so we need that influence to come through. And so we shouldn't be thinking in terms of measurement of explicit retrieval because that was actually a red herring in the first place. What we need to be doing is thinking in terms of the kinds of retrieval, but what I what it really is is runtime effic efficaciousness, efficacy in doing the kind of stuff we want people to actually be able to do with memory. And then we measure that like, okay, here's a set of instructions. Now, carry out the task, go right quickly as you can. Okay, what if we repeat the instruction? What if we inject something during the instruction in a certain point? um how does that either how does that influence negatively or positively the actual capability to keep going with the instruction set and we we could call this understanding but we can now see that that's not that's too vague and also to specific a word right there's variance there's degrees it's not like you understand or you don't understand um the the extent the the extent to which you're able to finish a sentence meaningfully is not it's not binary like you either completely forgot what you said in the beginning um or you're uh or you've got it in pristine form. It's that it's influencing uh what you're doing and and we have to so we have to have softer measures that are able to measure sort of kind of efficacy in this way uh that it's not dependent on sort of this binary. Okay, can you retrieve it or not? That's far too crude and frankly a misguided um misguided measure. So that's what I would I think is is maybe a really interesting project here and it's and it's twofold. One is to maybe rethink a little bit the the kind of things you want to measure. Um because that's not what's historically certainly measured in the soal short so-called short-term memory uh span window of time. Um but that's a really really important span. It's like finishing your thoughts. It's being able to compress in real time. And and these are all conjectures. I don't even want to commit to this. So something we're doing right now when you're listening to me is you're compressing this stuff. You're not representing it as the explicit tokens that I'm saying. You're doing this thing, but you're doing it in such a way not that you can retrieve it, right? Cuz what the hell did I say 30 seconds ago? You have no idea you can't retrieve it, but I promise you it's influencing your understanding of what I'm saying right now and your ability to then respond to it. As long as you know, if you know what I'm talking about, if you've lost your way entirely, I apologize, but if you're still following me here, then the influence is continuing. And so, we have to measure this in in a in a new way. Um, so psychology needs to think of this a new way for in terms of measurement. But that's number one, right? Measurement uh capturing what this thing really does even specifically. Let's just think of the the what historically thought the short-term memory window and but let's we'll start with that. we can elaborate further. Um, but that's number one. How do we capture it? How do we measure the the really the interesting the the the real thing that we wanted to do? Um, well, first of all, that that it's meaningfully doing. And then second of all, that we wanted to do. And then once we have what we wanted to do, now we can get to the hard work and and maybe you know, I think it's in some ways more difficult work of okay, what can we do about it? um what do we if we have the right measurements what are the possible interventions that could be helpful in doing it more effectively in doing doing it more efficiently. Um and but you need to you need to solve one before you solve two to some extent but you can also try to solve these in concert. Don't wait. Um just try to be more effective right away. Right? We want, you know, we want people to be able to understand information better so they can perform some task or explain it back to you. That's not hard to measure. We can start with that. Start with pretty crude measurements of did this person was this person able to perform this task based on my des my narrative description of what they're supposed to do? Um, and then mess around with that. um and see if there's there's a kind of measurable, testable, um uh quantifiable and and um setable uh you know, parameterizable uh factors that you can mess around with and then start to to see what the impacts are. Um maybe that needs a rethinking. I almost feel like that's too didactic and too um deconstructionist and and and maybe that's not the right approach. Um but in any case kind of the the the work before us in some sense is is kind of clear. Uh exactly how to go about each step obviously will will take a lot of auto reggressing. All right. So that's uh that's my thoughts for for today on this. Um I do think it's it's it's kind time for kind of a new psychophysics. And that's going to require uh a kind of rethinking of what measurement is in this space. Um but that's a good thing. Uh the the way we've been doing it hasn't been particularly effective. And so I think we need to start that today. Thanks for listening. Uh I'm on Substack Generative Brain. Uh you can also find me at baronhol.ai. Uh, and I'm also on XL/ Twitter.