URL: https://www.youtube.com/watch?v=ZH_U46ja430
==============================
Channel Title: ekkol√°pto
Video Title: Computational Complexity of The Brain | Professor Elan Barenholtz PhD
Publish Date: May 10, 2025
==============================

TRANSCRIPT:

Hey everybody, uh it's Elon Baron Holtz. I'm a professor at Florida Atlantic University and I'm working on uh generative theory of cognition in the brain and it's all based on large language models, the things that underly chat GPT. And the core idea is that the the basic math uh of how these things run isn't just a metaphor for thinking about the mind and the brain, but it is actually the fundamental core algorithm that is what our brain is running. So it's not even about explaining the brain. It's about what is the hardware of the brain? What's the software? what's the algorithm that it's instantiating and what I want to talk about today is this this idea of uh complexity which riddles the core enterprise of uh building machines that can do smart stuff and it's been uh it's an intricate and complex mathematical field that tries to capture what computing systems are and aren't going to be able to do uh and in and in what time. And the notion the the framework uh the computational framework is based on some something like a touring machine. And what I think we've learned in the last uh couple of years is that we can definitively say that that's not how the brain works. And then the the question then becomes okay well what lessons from computationalism uh actually may have relevance to thinking about cognition. So, I'm obviously going out on a on a in some ways on a theoretical limb, but I don't think it's I think it's a very firm limb. I don't think it's going to snap by saying that human cognition, at least linguistically expressed cognition like what I'm doing right now, all philosophy, science, ultimately math, math is going to be uh a tool used by this linguistic system. Um, but all of it is going to be folded into a an auto reggressive u model similar to what large language models do. And if that's the case, then the kinds of questions we were interested in asking in relation to comput computational systems are still going to be relevant, but only in regards to symbolic sort of classical computational systems. In other words, the computers that we have and the way they operate and they run is still going to be an area for complexity theory to to operate. question in my mind is okay are there lessons learned there that could potentially fold over to the human mindbrain and I think at certainly at at a high level there are commonalities but then there there are very distinct differences and maybe those are what are most interesting in some ways and about thinking about this contrast is that the the brain doesn't break uh the brain is not a computation ational system in that what happens at time step um you know t + 10 isn't necessary for doing time step t+1 and therefore there isn't this contingency brick in this brittleleness that's inherent to sort of symbolic computing where you have to get to the end of the argument uh to find out what the argument was such that you can now say what am I supposed to do with this input The auto reagent model says there's one rule, one update rule and that is next token and there's no contingencies built in and that means it's an extremely simple computational algorithm. Uh first of all uh it's it's it's simple in in the sense first of all you can write it down very simply. um uh but that of course you know comagor of complexity or something uh what you've got here is is is probably easy in some ways to instantiate in hardware because of its inherent simplicity. Um but I think even more deep than the simplicity is this unbreakability. So you know computer programs hang and and they and they loop um and that's because of this inherent brittleleness of this this this contingency this dependencies uh that uh it goes beyond just next token. But if you can solve things with next token that means you can't f up the system too hard. Uh because what can happen is like a stream running down water. It's going to hit a rock. It's just going to go around it. And then it's that's what the stream does and it's computing that. And so what you throw at it and that's you know all the context whatever is going on in our uh sort of computational environment that goes into our input is what shape the stream is going to take. But that's called computing. And there's no such thing as the stream saying wait I wasn't supposed to do that go back up and start over. Um no the stream runs. Now in the case of cognition uh in the case of of human cognition of course you got to think about functionality. It's got to run and do something. The stream is computing something of course and it's not just defined within the stream. You can build uh an autogressive system that that spits out your nonsense. Well I mean of course take any untrained transformer and it will do something. Uh, and it it is autogressive and it's doing the computation so to speak it's supposed to do, but that's like a stream that's and maybe the metaphor is going to break down real fast, but you know, stream that's just going off in all different directions and isn't sort of actually computing a shape of a trajectory, which is, you know, we can think of it as a stream as doing. Um, we want we want our autogressive computation to do things and and it does do things. uh and and of course that's the essential question is how do you build something that does stuff and not just language by the way but maybe other stuff too in this failsafe way um I think that's that's the question the new question in some I think um of of psychology of neuroscience of I I would say even philosophy um whatever this amalgam is that's trying to figure out the nature of thought and and computation And is it how does such a system that's just doing next token mind you've got uh you know the residual you got the context it's it's and you and you can represent that in very rich ways um but you're still doing this kind of next token how do you how do you get utility out of that the kind of utility that we know we have um this is this is what the the new science the new field has to has to do has to figure out um how do you build things out of that um but I think it's a very key poor insight um that there's an anti-brittleleness inherent in this kind of building system this way. And so this is what evolution, nature, uh information itself, computation itself sort of converged on as being the solution. Anyway, thanks uh for listening. If you want to subscribe, I have a Substack. Uh it's at GenerativeBrain. Uh you can also find me at baronholz.ai. Uh I'm also sometimes on x/ Twitter. Uh so check that out as well. And uh hope to see you again next