URL: https://www.youtube.com/watch?v=OftXY62-6HU&t=674s
==============================
Channel Title: Elan Barenholtz, PhD
Video Title: Beyond Next-Token: Why Autoregression Might Run the Brain—​and the Universe
Publish Date: June 29, 2025
==============================

TRANSCRIPT:

Hey everybody, Elon Baron Holtz, co-director of the machine perception cognitive robotics lab at Florida Atlantic University and I am working on an auto reggressive theory of cognition. Um, and today uh I want to talk about the potential extensions of the sort of auto reggressive framework. So, if you watched my uh theories of everything video, you probably already know that I believe that language is designed, for lack of a better word, to be generated auto reggressively. Uh it's it's in the inherent structure of language itself. And our brains are channeling that structure. uh I don't have a very specific theory as to how the brain is instantiating this. Uh I think that the way we have to think about this now is okay that's the computational structure. It's next token prediction something along those lines. Even if it's not fully autogressive in the in the sense of uh literally next token even if you think that we do prediction beyond next word I don't think so. But even if you think you do, uh it's still autogenerative. And that's the idea that the the structure, the geometric structure of the the corpus of language, the thing that we've learned uh since we were infants, uh the thing that the machines have learned by churning through uh all of the digital text in the world, the the structure is there and the structure is what allows for generation. You don't need anything else. Right? That's sort of the key uh insight of the theory. uh the autogenerative component is that you don't need anything else to do language besides language itself. the corpus, the body of language is sufficient. And that's proven in some sense. Uh except for the the haters and the naysayers who will say, "Oh, no, no, it's not really doing language. It's doing stochcastic parading. It's just doing some sort of pattern matching, whatever that's supposed to mean. Uh it's not really doing language." I think that's indefensible at this point. I think if you spend some time with these systems talking about the most obstru uh you know give it a give it a narrative uh plot and it it can uh you know or or hypothesis uh a scientific hypothesis uh or give it a a coding challenge and it can generate uh as well or better than most humans. Um and the idea that that's sort of an orthogonal completely different uh approach to me seems highly questionable. uh does that mean there's fundamentally exactly the same algorithm underlying it? Uh not not at the instantiation level. Uh so as I've said transformers are a particular flavor using attention in order to do next token that is one way to leverage the inherent structure of language. There may be others. Um is there quantum for example in the brain that's doing this? I'm I'm not I'm not weighing in on that per se. Um if you watch another video which I hope we can link maybe in this one that I just did with uh Will Han, we kind of get into this question uh you know is it possible the brain is is using other kinds of exotic uh kind of physics even even things like quantum in order uh to do cognition. I I think what large language models show us definitively is you don't need that in order to solve the problem which means that the the solution sort of the computational solution is there. uh without introducing anything like anything exotic in that sense. Now from an efficiency standpoint and things like that uh it could be that the brain brings other things to the to the table but the truth is the brain is this highdimensional uh kind of perfectly uh suited embedding space where you you could do something uh like uh the what the large language models are doing. Um and it has things like that things that are poorly understood like backwards projections which may actually be an instantiation of the kind of recursive uh process you need in order to do uh next token prediction. Um, so that was a long way of uh of sort of saying that's not what I'm going to talk about in some sense because I want to set the stage for the idea that auto reggression may be more fundamental. Um, that there may be other first of all cognitive um cognitive functions besides language that are auto reggressive. And then I'm going to speculate a little harder and propose something that's to some extent outside my wheelhouse um but that I have had glimmers of uh sort of an idea about which is that physics itself may be better characterized as a kind of auto reggressive process rather than uh the the current uh uh the Marovian uh kind of men um uh framework which basically sees the universe as having no memory. Uh that the the the universe is instant to instant. And if you think about uh what what calculus is, calculus is in some ways an a way of of kind of turning uh the continuous uh into the instantaneous um and saying, okay, there's a moment, right? There's a sort of there's acceleration at this moment. Um and it you don't have to stretch back in time uh and you can actually predict everything from moment to moment. And uh what I've uh what I'm proposing is that a different framework may be needed to truly understand what uh what's actually happening in physics. Uh I think that first of all conceptually there might be a sort of grand mistake uh in thinking that way and then perhaps uh the hope would be that this could actually lead to different frameworks for actually thinking about and doing physics modeling uh in a way that we could maybe even have uh novel frameworks novel theoretical frameworks that even could make different predictions. Uh I'm not waiting into uh anything like you know string theory or anything about sort of the fundamental uh particles and all of that. Um but I'm just sort of talking at a at a fairly high level about the idea of the universe kind of unfolding um unfolding in a way that is best captured by the this kind of auto reggressive process. namely that it's not like you're adding a moment uh to the current to the just the most recent moment but rather uh what's happening is the there's there's a a larger there's a trajectory that is determined by the past leading to the present and then determining the future but the trajectory is uh reaches back further into the past. Um, okay. So, that's sort of the the the broad question is how far can we push uh these this auto reggressive perspective and how much of a reframing does it allow? And the reason I think uh it's potentially very powerful is because it is really it's a fundamentally different way of thinking about computation uh in in the broadest sense. Uh what is happening in the case of auto reggression? So let's go back to language models which is the case that we're uh I think we solidly can say this thing works to do something very useful. Um and it's it's computationally happening uh in this in this kind of exotic autogressive way. Maybe not exotic. I guess that's what I'm proposing. Um so so what's happening in the in the case of these language models? So let's let's uh back up to that for a second. So we're all familiar with the idea of of next token prediction. And so the idea is you've got a sequence. Let's say it's uh you know um I pledge allegiance to the uh right now what's the next word if you're if you if you're from America and you're of a certain age I guess they still do it um you you know that the next word is flag um and so you've got a certain uh input sequence I pledge allegiance tothe' and then basically the idea is uh you can ask the model or you can ask a person what is the next likely word to be I always say that the tokens and words are not exactly the same thing but we will gloss over that technical uh that kind of level of granularity and we're just going to uh use the word word uh for tokens. So uh what's the next word? And so the idea is that you can uh build a model that can predict what the next word is. It's it's it's turned through an enormous amount of data in the case of large language models and based on that data it's learned uh sort of the the patterns in concept space whatever you want to call it uh but within this highdimensional embedding it's it's it's actually encoded all of the words uh that it's seen in such a way that the relations between them now gives it the appropriate ability to to to sorry gives it the ability to predict predict the appropriate next word and the autoagressive piece is just one step further. So, uh you could think about for any given sequence you could say what is the next word um and the model has been trained to do that. Uh the the magic happens when you say okay we'll take that next word and we'll add that to the sequence. Uh and so I say pleasure alleions to the flag and then you take that entire sequence put it back in the model and then run it again. And now it's just going to do the same thing. uh it's going to say okay given a sequence I pledge allegiance to the flag what's the probable next uh prob next word and in in the real models uh the way they work is actually they generate a distribution and it it'll have uh you know in this case of it will be the sort of the most highly likely uh next token next word but it will also have a distribution of other stuff other words that could be there I probably shouldn't have used this example because it's very constrained uh and in some sense there the distribution it will be very sharp uh sharply around uh that very specific next token. But you can see I want to mention the distribution idea because this is how uh these things can do things well beyond uh you know memorization. uh they they can they can tell a story and the story can go in meandering ways and the next time you ask them to tell the story uh they they'll tell a very different story and that's because they're not actually well they're not deterministic at least in this way because they have uh in in a simple way because they uh they they they create a distribution and then we'll choose uh the next token but that's a level of detail we didn't necessarily need to get into. So uh next next word and then you take it feed it back into the model and then you go from there and then you just turn uh you keep doing this successively that is what the large language models are doing they're producing the outputs uh word by word and that might not seem so radical okay it's sort of uh you know do a pretty straightforward prediction and then just repeat it but the idea is that that ends up solving language And the insight from that is that what's happening in these models is not when they're learning uh when they are learning to do that next token prediction and they're learning that geometric structure. They're not just learning to do next token prediction. Uh that's that's in some ways how they're trained. Um they are given uh that task over and over again and that's all they ever have to do during training is to produce that next token. But in the process of learning that they are learning much longer range kinds of relationships. They are learning in some ways not just to predict the next word um but they are really learning to predict the word that's going to predict the next word and then the following word. They're learning this unfolding. So one way to think about this is that the models uh are uh are are actually representing a sequence uh at any given moment. They've got a sequence that's in there that's that they they have in their embedding which is this sort of high dimensional representation of each token and then you've got the entire sequence in there. When they add on uh a next token, what we're what they're actually doing is evolving this this entire sequence. They're not just saying there's a next word uh because that next word is going to get tacked on to the sequence and it's going to serve as the next uh the next input. What they're learning is how sequences themselves evolve because the model is taking into account the fact that when it produces that next token, it knows that that next token is going to end up as its next sequence. and and and the sequence is is growing uh as and incrementing now it's never told this explicitly right there's something emergent here u and I know that's a loaded word uh but you what you see in these models by virtue of the fact that they're able to think long range about the future right if you ask it a question uh I don't know is auto reggression a good theory of of the brain and it might say something like well you know current uh the the current the gosh why am I getting stuck on this of all things uh right uh the scientific data right now is maybe somewhat speculative or something uh that word is when it puts that word is the current current scientific data is right that word is it's it it doesn't make sense to put that word there unless you know something's coming after that right the word is is is inherently sort of a bridge word and that word is anticipating what's going to come next um and very appropriately and we we we can see this in the models. It's it's it's should be a shock uh the first time that and it was a shock to me if you take this you know just to see it at its face value when you find out that they're just doing next token. You're like that can't be what are you talking how is that even possible? uh how could they be thinking about these very how could it be plotting what seems to be plotting a very long reply that's going to take you know you ask it a multi-pronged question and it's going to say okay well let's first answer the first the first part of your question and then so and it does that in a way that builds up to the response to the second part of your question well how is it doing that how is it possible that it's anticipating what's coming uh if right now all it's doing is next token it's just thinking very short term and so the answer is that in learning these sequence quences and learning how to evolve the sequences. Uh it or rather one way to put it in learning to do next token and learning it from many long strings of sequences that that it's been exposed to. What it is learned to do is actually not just do next token in the simplest sense. What has learned to do is to evolve the sequence. It's to evolve the the sequence in such a way that it maintains this kind of coherence. It's a trajectory. Sorry to use jargon, but it's a trajectory through embedding space. Um you could think of the sort of uh the representation of the sequence as being embedded in this highdimensional you know so it's it's it's this big old uh space made up of vectors and you know you could think about sort of a cloud or something like that still working actually right right now actively working on uh with with a former student um we're working together on a project to to to actually visualize this what what it means to have this sort of cloud of points uh that's then emerging that that's evolving over time um as you add the next token. Uh you can really think about this as as a kind of evolutionary process of the entire sequence. Um so that is uh but it's incontrovertible uh in the sense that you can't argue with the fact that next token does this kind of prediction. Uh there were there was I think I mentioned in a video and and uh and something we can link uh there was a very cool paper from anthropic about actually being able to sort of decode the activations in such a way that you you can see this kind of prediction. You can see the rhyming word coming that's going to it's going to rhyme with uh when it's producing a poem. You could sort of see it being already reactivated before it ever gets to it. Um so you can sort of see in the weights but it's you need to be careful. It's not thinking about the future. It's not generating the future possibilities in the way that we may think like when we think about the future because we're doing it auto aggressively. We will actually think what's going to be the next token and we we we sort of actually play it out in our minds. It's not doing anything like that. it's a single pass and all that single pass is saying what's the next token but in thinking about what's the next token there's a certain sense in which future tokens for lack of a better word are and it's not that's not the right word because the activation isn't really a token but whatever um the the future is kind of impinging on this process uh in uh in the present uh just to do this this next next guess and the way to think about that in my opinion uh I just have to work this out in more detail is this kind of evolution of the in of of it's it's it's an evolution of the sequence itself and so the sequence in some ways because of language's structure the sequence has within it this kind of predictive structure such that there's the the future the the so I I use the term potentialities um in relation to sort of what the brain does uh or or what a neural network does it's got a potential to produce the next token it could produce produce from a different input, it could produce a different token. But we could also think about the sequence itself sort of having potentialities built in it that that the distribution is sort of enlenqu. Uh where is the sequence going the models can do that and and that's how they do next token but it's inherent again because it's in the geometry of the language. It's inherent in the sequence. The sequence contains within it the future of that sequence. Um it can be nudged in different directions and we can sort of again think of like a dynamical system. uh it's got a trajectory that's kind of determined not just by the previous state by by the entire history um and it's moving through embedding space um and it's going to go in certain directions um and those are kind of those are actually carved out beforehand in some ways you you think there there are multiple paths again because you you can choose uh I mentioned again the distribution you could choose a different output instead of I pledge allegiance I I pledge uh my support right if you at that point uh you you could have a different output for I pledge um what what you might say after that depending which one you choose and in the models it's it's a little bit um you know they they they introduce some noise so they can they can choose something that's not just the most likely and then you end up on a different trajectory but these are kind of parallel uh paths that the the sequence itself can take um and then the models are just sort of plotting and charting those paths but these paths are in some ways already predetermined based on the structure of language itself. Okay, so that's sort of the uh the core idea of the idea of evolving trajectories, evolving sequences um in in the case of the language models. And then the extension, the potential extension is well, okay, let's back up a second. Um you know, where did this magic come from, I guess, is is a is a key question. uh where did the idea of evolving trajectories that are that have this history um and that you can add on to uh come from in language? Uh it it seems magical. It seems a little bit too good. And I have you know uh now deep questions about sort of the origins of language that not I have I think we as a species have uh new questions about the origins of language um in a way that we didn't have them that we didn't have before because it the computational richness now is is in some ways much greater in some ways it's simpler uh right because it's this one trick just guess next token uh based on the geometric structure of of the relations between words and that's it. You don't need fancy syntax. You don't need the sort of chkin grammar or anything like that. You just have to do this kind of prediction. Um so it's that's when I say I say it's computationally simple but it's very very far from simple to build a body of language that has the properties such that it's going to generate this way. So the mystery is now not in our brains and how do how are we able to produce um language but the mystery is now in how does language have these properties in the first place such that it's generatable this way it's autogenerative in this way that's uh sort of the key question now I think for linguists uh for for the for the field of linguistics um and more generally right I this is a question that this concerns us all uh in some sense like where on earth uh did this mysteriously rich complex kind of uh uh um computational system come from? And you could say, well, it came from our brains. But to me, that's sort of begging the question like the brain seems to be well suited to do this. Um the proof of the pudding is in eating, right? You you can do it. It works. And so our brains are are able to do it. But now that we've captured language in a bottle and we can see it for what it is outside of the brain uh and that's that's that's that's what's new uh is that we can actually see that it has so we can see it has these properties sort of brain independent properties um that it's that it's autogenerate. where does that uh come from? And now we also have I think not just the idea that it can generate itself, but we also have some clues about how it's doing that this kind of unfolding trajectory predictive structure built in to uh the body of language itself. And so my uh further hypothesis so I think I mentioned I've I've well there's a there's two about language uh or I they're not the hypothesis is that the brain is doing the language the same way. The there's two uh observations about how large language models do it. It's autogenerative. It's auto reggressive. Uh the claim is that the brain is is doing that something similar. this auto reggressive piece. I'm now extending that the idea is that um the brain may more generally be doing auto reggression and that is uh based on well this observation that language seems so well suited to auto reggression um that it seems like our brain probably have this uh kind of machinery this cognitive machinery already in place and then language somehow is was built to leverage that. I think it's still deeply mysterious how language ends up being so good. Uh how language is able to both sort of autogenerate um and do it in such a way that you know our brains can handle it. Um and also describes the world and I'm not saying describes the world in the in the sort of naive representational way because I don't believe in that. Um but it is an effective mode of communication for coordinating behavior. Um and probably for sort of internal kinds of of reasoning as well. We reason linguistically um and we come up with uh actual conclusions based on that reasoning that are effective. Uh it's functional. So language is not just this autogenerative uh kind of process. It's a really good one. Uh it's able to do all the things that we know language is able to do. So how did how did it get so good? Uh where did it come from? I think big questions. Um but the hypothesis here is that it didn't show up in a vacuum. Um it's not a new computational trick new to sort of the universe when language arises to be to have a kind of autogenerative auto reggressive process. uh that there preceding language there presumably were other kinds of auto reggressive processes already happening in brain in in human brains and probably in other species's brains as well. All right. So, uh I I'm I'm inclined not to think that there was some sort of you know radical departure computationally speaking in terms of what the brain does. I think there may be a quantitative uh departure in the case of humans maybe more layers you know more equals different uh is it's possible that if you add some additional layers then language becomes possible uh Dan Elton that's the name of his blog the substack more is different okay uh so yeah Dan Alton has a has a a is it is it substack yeah substack um so more is different I don't know where the term uh the phrase originates from I learned it from Willilhan uh but I think he stole it from somebody Um, so maybe we can link where it originally comes from. Maybe Dan Elton does that. Um, but you know, maybe you add these layers and then lo and behold, you can have these abstract things called words that uh that can operate in this autogressive kind of um computational uh architecture. But it seems unlikely that the entire core architecture itself was new uh to humans is new to humans. Um, so what about other stuff like uh perception and uh navigation, motor motor control, all of those things? Are those potentially also auto reggressive? And I will admit uh off the bat that the evidence for this is certainly far more speculative. Uh is is in the case of language, we've got it. It's like it works. It runs. It does the thing. We don't have uh an example to my knowledge of anything remotely close to that uh where what you're doing is generating say sensory or perceptual tokens if for lack of a better word um that you've got those kind of in in this embedding space and then if you think about if you let's say you want to execute a motor program or you want to think about how am I going to get from point A to point B um and you you you sort of generate the internal process that that's happening autogressively. what I can point to uh is sort of auxiliary kind of anecdotal evidence from the way uh you know we know that minds work. So so typically if you think about a some sort of sequential process let's say a visual process I have to get uh you know I have to I have to let's say I need to drive somewhere and I'm thinking okay I need to grab my keys I'm going to grab a bottle of water on the way uh and I'm going to go to my car. We don't see that in a flash typically. uh what we do is you know and I can't speak for everyone um but I think many people most people uh they will actually sort of generate the sequence uh when they're thinking through the steps that they need to take they're going to generate the sequence there's there's actually uh some evidence you know the quantitative evidence for this uh coming out of the imagery literature and adal debate uh the the imagery debate is is imagery is visual imagery actually like visual real visual processing or is it actually happening at sort of a a more semantic uh kind of level? Not going to wade into those waters too hard, but some of the early evidence uh for the idea that it's truly imagery like uh come from these experiments where people have to describe some they have to perform some task and the more you have to do the sort of the further the space you have to travel uh in your mind uh the longer it takes people to do uh the imagery task. And so that was sort of taken in in a I would say you know fairly simple level uh to indicate that okay it's sort of like uh what you do when you're actually seeing things you have to travel through space in perceptually and and and so when we're doing it when we're running in our minds we're doing that similarly um I want to leave aside whether it's really visual or not but the sequentiality of it and the fact that it takes time to me uh is sort of a very important clue that It may actually be auto reggressive. And in fact, any kind of uh cognitive process that takes time to run. Uh you know, thinking through a problem, a math problem, a life problem, uh you know, a significant other problem. Thinking about okay, if I said this and then they said that, uh what would happen? Uh you know, or or thinking about what happened in the past, a memory that you play. Uh so episodic memory where we play these things out. Uh and it takes time to think about it. If somebody is sitting and staring into space um now sometimes they may be thinking about absolutely nothing right but in many cases uh if you ask what are you thinking about they'll tell you what they're thinking about and what does it mean to think about something so my conjecture is that thinking about something is actually running the auto reggressive process. Why does it take time uh in a in a neural network? And if our brain is a neural network, if you have a problem, you you introduce the problem. Here's the solution. Um what is going on in why why don't you just get that solution instantaneously? And by the way, in some cases, you certainly do things like visual recognition. In most cases, it's instantaneous. Sometimes you see something and you know immediately something's right, something's wrong. Uh a ball's coming towards you, you got to catch it. Uh maybe that's not the best example, but uh there's there's things that uh that that they're decision-m processes, uristics that are very rapid and in some ways seem to not involve this kind of sequentiality. I think by the way, you know, Conorman's uh thinking fast and slow, there may well be uh a very strong uh relationship to what I'm getting at here. Um so anytime you have this kind of sequential uh any kind of thinking takes time the proposal is what's taking time is simply auto reagently takes time. Why? Because you have an input uh a certain input you produce the output you have that's one pass through the system. The system can't produce the entire output uh that you want. Like for example what's you know uh how do you tell me a story uh about something? You can't just produce the story. Uh you can't say boom, here it is, you know, and and the models similarly can't just do that. They they can't just say boom, here's the paragraph. Here's the here's the chapter. Instead, they have to do this sequentially. And why? Because that is how language works. Uh it's built with this in mind uh that you have to do it auto reggressively. You have to run it through, produce a single output, take that and then tag it on. So similarly what's probably happening in the case of say visual imagery uh any sort of thinking that takes time is we're probably doing this auto reagively. We're probably taking uh the outputs of our own mind whatever right and again do I have a neural uh kind of um uh actual fully fleshed out uh account of this? No I don't. Um there are bad the most I could say is there there there are these backwards projections. uh there's certainly things like that look like recurrence in the brain and maybe that's how it's happening but I I don't have much more to say about that right now. Um but the the hypothesis is computationally it makes a ton of sense that you would see certain kinds of thinking take time simply because uh you need to do the autogressive process meaning one pass through is not sufficient. You have to take the output of your own thinking system and then take that and then that uh add that onto the sequence and then run it through again. Now I don't you know there's this certain visual imagery that I'm having right now of sort of taking the sequence and putting it back in the beginning which is one you know it's kind of a convenient way to think about it but if we think about it sort of evolving as opposed to feed it back through right because the the evolutionary story of this is not that the that you've got a sequence and then you tack on a next thing and then you just run it through. It's that the entire sequence itself is kind of evolving to that next token. it's growing. It's unfolding um in this way. Uh that's that's a little different than just saying guess next uh next state. And so if we're thinking about brains and think about what they're doing, it may not end up being useful to think about it as sort of like there's a there's a front of the brain where you feed things in and there's a there's or back, I don't know. Uh right there's there's sort of the input side of the brain uh and then the output side and then it take the brain takes the output and puts it in the input. It's more likely that we could think of this as some sort of uh dynamic evolutionary process where the neurons where the states of the neurons are are are changing dynamically in such a way that you're getting the next state. Um but it still has to happen sequentially. So it's is that's built into autogression that time the time element is it's it's inherently a dynamical process. Time is built in uh in some sense computationally speaking. What kind of time scale? Right? It's that it could be uh and it's something we talked about I think in a different conversation the time scale could be you know microsconds nanconds it could be but if you extend this it could be over much larger time scales and this this is something I we talked about also in in a in a previous conversation maybe we can link it um is you know sort of thinking about uh in the brain that there there are there are much longer time scales this conversation is taking place I've been blabbering on for I don't know half hourly at least something like that. And I'm still talking about what I started off the conversation with. Those tokens, the things I said early on are not just seeds. It's not even the right way to think about it. They are continuously still guiding what I'm saying now. Um, and that's that's a way of thinking about this. So this this evolutionary unfolding. So it could take place over, you know, uh, in a very short time periods, but it also can take place over potentially much longer time periods. And so I don't know what the what the limits are and but I'd like to think that the brain's evolutionary process in this way um possibly could extend over much much longer time periods than we've historically certainly thought about short-term memory working memory. I think those uh those kind of models of short-term this this very time limited uh you know 15-second kind of uh window is probably on I I I'm going to come out and say it. I think it's it's an artifact. It's it's actually it's it's a mis a misleading artifact of the way that people have measured uh this kind of thing. I think if you think about guiding next token, guiding what I'm going to say, uh the the working memory extends certainly much further back than 15 seconds. That's for a different video. Um I do want to take down the concept of of 15-second working memory even though I still teach it in my cognition class. Um it's I think it's fundamentally wrong. But uh leaving that aside, right? Leaving that aside, the idea that there are um that that there is this sort of continuous dynamic unfolding that could take place over seconds, over minutes and and and perhaps even much longer. Uh I think is is sort of the cooler idea. Um so it may apply to more than uh certainly more than language. It may apply to other domains of cognition when we're we're thinking about or and or and and now now uh it's not just about like short-term how do I get you know I'm going to get into my car I need to pick things up but it's planning your day and it's planning your life um that there's this potentially some evolutionary process where everything you've done till now and I don't know if it's everything and maybe there's there's lots of lots of loss uh in sort of in in the residual or if we even think about a residual right there's maybe the information is genuine lost in some ways but that there is this dynamic unfolding that could take place over a much longer time period. Um so not just linguistic and not just recent history. These are two of the main themes that I'm really focusing on in terms of extending this uh to other domains of cognition. And then beyond cognition, the the the the sort of more far out idea uh but I that I I hope uh may people with far more knowledge um and expertise could weigh in on is the idea of thinking about physics itself that the the universe itself uh is kind of auto reggressive that that instead of thinking about states leading to states uh in this marovian way uh in fact what we're see what what the universe really consists of is this kind of dynamic unfolding Uh and so you know from the from the big bang and you know the singularity uh there there's a certain you know seed state is one way to think about it and that we are what we are witnessing moment to moment is still an unfolding of those quote unquote initial conditions and and that that's not really a controversial view. I think a lot of uh you know any if you if you sort of deterministic view of the universe we can leave I'm not getting into you know quantum weirdness and all that stuff maybe for a different day. Um but the the unfolding in some ways is it's thought to be deterministic. Uh right that the the if you believe in determinism uh if you think that the the the maybe the initial conditions at the you know origin of the universe uh actually determine the my hand is in this position right here right now and I'm saying these things but uh so that that idea in and of itself is actually fairly conventional leaving aside you know uh sort of quantum uncertainty and things like that. Um I I don't want to weed into that. Um so this determinism is is sort of okay that's how physics works you know state uh you know is uh the universe at at time uh you know whatever t t right now t minus whatever you know uh infinitely uh um small time period for now uh is fully determined uh what what's happening right now is fully determined by that previous time scene. What I'm saying is that that determinism uh the way we're we've been thinking about it is really that uh it's sort of chopped up into uh time slice is such that uh each time uh slice is is determining the next time slice. However you think about um you know the the uh how thin you can you can slice it. Um right it's it's again with calculus you can sort of do you know instantaneous change and things like this. um uh not going to get into again today, but you know whether that's sort of a math trick uh well I am sort of getting into it. I guess my argument is in some ways that that's a math trick that is really glossing over or or kind of framing uh the what's happening in physics in such a way that we can do the math that way so that that it works uh that we can actually do this kind of instantaneous uh sort of rate of change in order to do prediction from one moment to the next. And then you can just run that and it unfolds and you end up with sort of a dynamical system that that does the stuff that physics do. But it's still sort of metaphysically uh certainly is the idea is that it's marovian and there's one each time slice determines the next time slice. And what I'm proposing is that that maybe sort of fundamentally wrong way of thinking about it. And instead what might be happening uh is to think about that big bang as still actually influencing what's happening right now. Uh that the entire sequence since that time is continuing to generate. And so there's sort of longerterm dependencies that may be happening uh that reach back all the way to the beginning because the unfolding is of the entire sequence. The entire sequence of the past the the present contains the past. I call it the pregnant present. Uh the the and I by pregnant present I what I meant you know first first time I used the term is that it was pregnant with the future. Uh that the the like in the large language models what it's producing right now when it says is or for it's inherently actually taking into account the the the entire trajectory that's going to go through the future path. But the but the present is also potentially pregnant with the past um in that the entire sequence is determining what's happening now. not just uh the the sort of the current state but literally kind of what happened in the past is reaching into uh the present maybe that's the best metaphor but that unfolding is taking into account the entire sequence since the beginning of time and you know if you accept this kind of view it kind of changes things and uh I I haven't and this is where I need physicists to jump in here um I don't know in what to what extent this actually makes you know potentially is there's an opportunity for modeling physical systems in a completely different way such that we'll capture uh actual details that we wouldn't have captured otherwise. Maybe even make better predictions. Could this account uh you know for other kinds of phenomena like like quantum weirdness phenomena? Uh if particles at the beginning uh were in relation to one another, could non-locality have something to do with the fact that there's not really a break between the the the past and the present, right? When we say these two things are separated out in space, well, but they started off at the same point. Uh they started off together. Is that unfolding maybe a better account? uh the fact that it's sort of this the evolutionary dynamic unfolding may be a better way to capture what's happening in the case of non-locality. We're like well but now they're totally separated. How can what happens to one affect the other? But if you understand that what's happening uh is not actually these completely cordoned off time slices. The past is the past. It has nothing to do with the present. Well, maybe that's not right. And maybe if we're thinking about uh the present is being a result of the consistently influ consistent influence of the past then the then that previous state of these particles in the uh the fact that they started off together uh is still influencing their uh what their manifestation right now. What happens to one sort of affects what's happening to the other because of that. Again not a very well articulated u uh view um but I can sort of you get an inkling of it. um when you start thinking this way and that's um just at the very much of the beginning of this process about thinking about other kinds of uh evolving uh states sort of the universe as as having this sort of dynamically evolving state um but where it's where it is actually um continuous in the sense there sort of this causal continu continuity um that the past is continuing to to impinge on what's happening now um and I guess uh where can you go with this uh is is this in fact a complete reframing? Is it you know mathematically going to end up being completely identical to uh sort of the Marovian uh perspective? My my uh my hope is that there may be actually novel insight in thinking about it this way. Uh and maybe even novel prediction. Uh insight would be in the you know thinkings like things like quantum entanglement and things like that. Um where we have these really weird data. What on earth is going on? Um, and you have accounts of that, um, that many people, myself included, find extremely unsatisfying. They they they just don't hit sort of, uh, sort of our our common sense um, uh, notions of of of anything. Uh, it's not just that the physical universe doesn't work that way. They're sort of like that's not what we mean by particles being separated in time. It's like the physical theory itself seems to be at odds with uh, with the data. Um, and then you just have to come up with some sort of name for it. It's they're they're entangled. Uh it's it's action at a spooky action at a distance. Um spooky, right? Well, if it's spooky, then that means you're kind of saying your theory doesn't actually encompass this. Your theory is broken. Uh whatever. Maybe there's another theoretical framework that doesn't have to get spooky uh in the sense that we don't have to postulate kind of stuff that's outside the theory. You don't have to introduce a new metaphysics. um this might itself be something of a new metaphysics, but maybe it's it's uh actually capturable in a way that's palatable uh that that's that we can we can work with it uh in in some ways. Maybe even a physicist can work with it in a way that the these things have meaning within the theory uh in a way that we don't have to sort of um sort of have a gloss a sort of a metaphysical gloss like okay there's just some strange stuff. um no uh maybe the universe is unfolding in this way. Um and if you understand it that way, maybe some of these things can can potentially fall out of it. So that's that's the sort of the biggest idea um I would say I have in relation to this entire kind of uh this computational framework of autogression. And then if that's true that there's sort of it's built into the universe maybe becomes uh a little less mysterious that our brains are doing this so well. Um and that uh you know even language has this built in because our brains are of course they're the they're in they're there are they are a product of the physical universe. they're meant to leverage sort of the the information in the physical universe to do stuff for us. Um, and you know, when I come back to sort of the idea that the brain is is auto reggressive, uh, the idea is well, nature is autogressive. Uh, the physical world is autogressive and the brain is just actually built on top of that. Not just that the brain is autogressive like it's made out of physics and therefore it does. No, that the the sort of the computational structure that we have to built into the brain is channeling this inherent auto reggressive predictive structure of the universe uh of the physical world. Uh universe is just when you say start say universe certain people get turned off uh you know like oh man this is like out there but I'm just talking about physics. I'm just talking about you know the natural world. Um things follow other things in a predictive way. The world unfolds. I think we we can all agree with that like at a very sort of folk psychology way. in folk physics way things you know I drop something it falls down uh if it's glass it breaks and shatters into lots of pieces all of that stuff happens and it's and it's it's sort of a a smooth trajectory through space time like you know you can and you can we kind of have an intuition about how things move and change over time that's the kind of unfolding I'm talking about and the idea is that our brains simply capture that uh unfoldability of uh the physical world in such a way that ends up being very useful and then uh you know our perceptual system, our motor system and then the linguistic system is is built on top of that machinery, right? It but it's it does so in I call it a new physics, right? It's it's symbols and relationship between symbols um and prediction from that and not it's it's happening in a very weird way different than I seems pretty fundamentally different than um the way physics may be doing it but it's capturing the same fundamental autogenerative auto reggressive kind of uh computational um computation and so it it's it's more continuous this way instead of thinking about it as just like wow there's this entirely new kind of way of doing computation where you have uh the the this this geometric structure and using using this sort of predictive inherent predictive structure, you're able to predict the next thing and then run it through again and evolve it and all that. Uh if that was just language, then I'm like, okay, well then aliens build it. Um but if our brains already do it regularly, and that's because the universe does it regular, the physical universe does it regularly, well then at least you have something, some broad uh course out layout of how this really could have gotten here. Um, so that's pretty much what I wanted to share. Um, I'll be writing about all this on my Substack. I should have mentioned that my Substack is generative brain. Uh, or or I think you could just go to Substack and type in Elon Baron. Just search for me. Um, or just Google Elon Baron Substack and you will find me. That's where most of my writing is at this point. I have a couple of uh papers in various stages in pipelines. Some of it's going to end up on archive. Some of it's going to go through peer review. Um there's a lot here as as you can see. Um and I have to the the uh the scientific publishing process is uh slow and also requires a certain degree of uh sort of citing citation and continuity. Something we talked about in my conversation with Dan Elton. Um it it's not so easy to push through sort of a fairly radical new idea. Um but it's doable. Um, and so I hope to have uh uh peer-reviewed publications on on these very topics uh in the fairly near future. But in the meantime, check me out on Substack. You be my peer review. Uh I get a lot of great comments and uh also and uh I I put a lot of the stuff now on X as well. Um and uh that that is also I'm seeing uh quite a bit of energy around that. Um I'm getting a lot of really great feedback. Um so please check me out in these different venues. uh and uh comment, join the conversation. Uh I need feedback on all of this. Um because some people really hate it, some people really love it, some people I you know I see it as I do as sort of radically shifting our entire consciousness. I I don't mean with the small C, you know, like the the I'm not getting into qualia right now. Um but uh it is sort of a a mind-shifting kind of uh perspect change in perspective. Um, and make sure to check out uh my YouTube channel as well. Uh, you can find me. It's uh it's again you can Google YouTube Elon Baron Holtz or I believe the the handle is E. Baron Holtz. Uh, and and I think it also has the tag generative brain. I'm not so good at this social media thing just yet. Um, my my good friend Addy is helping me out with this. Um, and he's actually, you know, holding up the the screen to remind me. So, uh, I'm on YouTube as well. I hope to have more material on there. we're going to put this video this you you may be watching this video on YouTube um and so subscribe to my channel but more importantly than subscribing uh please jump into the conversation cuz as you can see I'm sort of trying to figure this all out um you know just like anybody um and I just happened to have gotten here kind of early in some ways. Uh I I one insight led to the other and kind of sedoku style like the auto reggress uh I make auto reggressive jokes. it's it's not particularly popular amongst anybody but what am I going to do? Um so uh you know it's it's one thing is leading to another and I would love help both in you know potent potentially extending this but also I want push back. I really really genuinely do. Sometimes it's snarky and you know it's just like this is the stupidest thing I've ever heard. Like words of course have meaning that's so stupid that you haven't given it a fair shake. Listen to it. make sure you understand what I'm actually saying and what I think the the evidence and data are uh before weighing in. Um but if you have something uh you know a very a substantive criticism um I have gotten extraordinarily rich very some really really smart people uh who are spending time commenting on YouTube um and it's been awesome. Um and I I there's over well over a thousand comments on my uh YouTube uh my my uh theories of everything interview which if you haven't seen it please check it out. Uh it's 2 and a half hours. There's some little shorter snippet that Kurt posted as well if you want to check that out. Um, but the the the level of comments has been extraordinary. Um, and there's there's there's an awesome community of people who are just care about this stuff. Um, and want to weigh in and I I really I hope to do I want to be part of that community. I want that community to be part of what I'm doing. Um, so please join the conversation. This is for the sort of the social media community which I'm just sort of learning my way around. If you have a podcast, um if you have a Substack channel, if you have uh any sort of uh public facing channel or or um blog or anything like that and you're interested in what I'm talking about, I'd be very happy to come on your uh channel to to weigh in. Uh you know, I I can submit for Substack. I I actually did a a Substack interview, Substack live. Um, and uh, I really kind of just trying to get these ideas out there a because I think they're they're important potentially important ideas. Um, I I I I am the author of them to some extent, but not really, right? I just sort of stumbled them like I saw something here. I was like, I I'm pretty confident there's there's something really important going on. Um, so first of all, I think these are really important ideas and I I want people to to be thinking about them. I think it's already generated a lot of uh really really interesting conversation. Um but as I said, I I really want um to hear what other people have to say. And so I'd love the opportunity to go into the public sphere. Uh it's it's going to, you know, into the the the town square and say, "Hey, this get on get on my soap box." Um but, you know, pelt me with with lemons or whatever um if you don't like what I'm saying. So, uh, if you're if you have a venue, a channel, anything like that, um, that you'd like to discuss these ideas and have me participate, please let me know. Um, I'd be very happy to do that. And you know that includes uh if anybody wants to debate me on this, if anybody wants to take me down uh again thinks that uh there's there's a a a sort of gaping hole uh or there's I'm making a fundamental mistake um and you want to take me on or you just think the evidence doesn't point towards this or you think I'm overstating the case. Um I would like to debate you. uh not because I'm such a good debater and I think I could take it down, but because again I think the this this process of sort of uh kind of adversarial process uh it really sharpens things. Um and and I think it could be very beneficial and and and maybe I'm making a fundamental mistake. I want to know, right? I'd rather find out now uh that I'm going off in a direction that that's just it's going to be fruitless. Uh so let's debate uh let's just uh discuss this. Uh anybody who who wants to do that on camera, we could do it live, we could do it recorded, whatever. Uh let me know. I have a lot more to say about all this and there's even more speculative ideas in here that I am uh hesitant at this point to share because of sort of the woo effect. Um I there there are soberminded phys sort of uh physical determinist kind of scientific uh mentality that has has gone a long way um in sort of explaining or at least predicting uh our universe um and the physical universe and I uh I I I'm somewhat hesitant to you know sort of extend too far into the sort of the metaphysics or something like that but I do want to share that uh there's some very very interesting kind of ideas, at least interesting to me. Um that you could sort of uh extend even beyond just talking about physics um per se in in thinking about some of these things and and some of it has to do with with consciousness, but it has to do with the idea of sort of of patterns um which is not a good word, but sort offormational patterns as being sort of the fundamental. sort of this this this it from bit uh kind of uh notion that that there are ways of thinking about things that where the the physical instantiation isn't quite exactly the right story. The phys the physics is you know the patterns in the physical world are really carrying out um a more abstract layer and a more abstract level. And if you start thinking about the world informationally, you think about dynamic evolution of information um as opposed to just physics, things can can start to get very interesting in terms of tying this to well let's say I don't want to I'm not going to use words because you know once you once you say certain words um it it turns off certain people and and really reasonably so. uh people make all kinds of claims uh and by pointing to sort of invisible physics right uh physics of the invisible some I think that's that's uh mysticism has sometimes been accused as being of being uh sort of a physics of the invisible and it's not a it's not a compliment uh it's the idea that well you could just postulate all kinds of stuff um and then you can we have whatever account you want the idea is a much more grounded kind of perspective here but thinking about what it means uh you know forformational Uh maybe the informationational level is the level we can talk about right now. Um but that's that's a good level. Um and it does all kinds of interesting stuff in in the in the case of language. It really is information that's unfolding, right? Because because the physical instantiation of words like written or spoken something in the brain, the brain is capturing uh some sort offormational process. Once you talk about as anformational process, well, now you've gotten away a little bit from from just sort of physics, physical determinism, and we sort of informational determinism. Well, well, then what what about that and and then you could get outside of like then for example just and just to tease one idea, you know, the inside and outside of your brain then uh and become much less meaningful. uh if you don't think about you know sort of a closed there's no such thing as a closed physical system especially if you think about uh this sort of long-term uh uh sort of evolve this this long-term trajectory where where the the evolution is happening based on things that happened along in the past right our brains are just part of this uh larger unfolding and then what's happening there is informationational unfolding happening through our brains and that is a really cool and interesting idea um and and I think it leads you to think about things differently. Um so I I have some sort of speculative ideas in that space but I think just that as a thought tool and a way of thinking about things uh the the the the space of possibilities possible thoughts uh becomes pretty different. um and and sort of our our maybe narrow uh sort of physical deterministic uh way of thinking about things may be sort of woefully inadequate uh to sort of to capture what's even going on physically but but then uh conceptually um so I I think there's almost let's just say it's sort of spirituality let's just put it out there um and again I just lost you know half of you uh but that whatever people meant by spirituality um And maybe many people many people meant many different things but perhaps there is a sort of I don't I call it a bridge or a way of of capturing something closer to that in a way that's grounded uh in a way that's meaningful that we can uh say things even maybe we can even make predictions uh we can we can interpret uh observable results in a way that's maybe closer to that than we had previously thought. So that's just a tease uh and some of the uh crazy ideas that are rattling rattling around in my brain. Um and uh you know stay tuned. Um and again join in uh if this resonates with you in some way let me know. Um let me know if it doesn't resonate with you for for sort of a a substantive reason. Let me know. Um but that's where I'm at. The last thing I got to say it like, comment, subscribe. These ideas won't get out there on their own. uh it's it's up to you uh to kind of shed to spread them uh to to people that you know who might be interested in them. Uh if you know somebody who might be interested in ideas then uh that's the right person because you know who might be interested in in in this kind of stuff. If you're one of those people well you're one of the weirdos and so am I. Send it to your fellow weirdos uh because I think a lot of them may be interested in this. I have, you know, one of the the big surprises uh of the theories of everything um interview that I did is just how much passionate response it's received. Um and it's it's obviously it's been very validating and very gratifying, but I'm just like, "Oh, wow. People really care about this kind of level of abstraction uh in a way that I I thought maybe I was, you know, was maybe an audience of one or that there wasn't a particularly large community." Um, turns out there's a lot of people who are kind of seeking uh answers or or ideas in this kind of space. Um, and that's awesome. Uh, so let's all talk. Let's get together. Uh, send it to people, you know, so that they can join in the conversation. This isn't my conversation anymore. Uh, it's it's the world's conversation. Uh, I think it's extremely important. Of course, I think that not only because it's my idea, though. uh it's because I really do believe that there's some key something as radical has happened uh in capturing language in this way. It's an insight into certainly what language is. It's an insight into uh the nature of our linguistic thinking which is enough to you know completely overturn uh almost everything we thought we knew about knowing. Uh you know philosophy and science are all linguistic uh pursuits and that that's enough but it may go far further than that. Um and so uh I really want to hear uh what other people have to say or or or I want this conversation to continue uh beyond this you know this uh particular instantiation of it that's happening uh even between these two ears. Uh so again send this along uh let people know about it um and I look forward to hearing from you.