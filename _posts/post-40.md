---
layout: post
title: "AI and Bullshit, a Moralist View"
post_number: 40
---

I've been trying to categorize the different ways people feel AI is wrong or "evil." I've looked at it through the lens of [systemic harm](/post-10), [frustrated ends](/post-11), and [imitative negation](/post-12). In the middle of it all, I keep finding the same thing: the [Romantic ideal](/post-21) of the authentic, sincere human soul.

Recently, I came across an academic version of this argument. It's from a group of philosophers who argue AI isn't lying to us or simply mistaken. It's bullshitting. Here's a [conversation](https://www.youtube.com/watch?v=SE33HBfsu04&t=297s) that lays it all out.

Their argument is built on the philosopher Harry Frankfurt's [definition of bullshit](https://en.wikipedia.org/wiki/On_Bullshit). To bullshit is to speak without any concern for the truth. A liar knows the truth and tries to hide it. A bullshitter doesn't care what the truth is. Their only goal is to be persuasive, to achieve some effect. The truth is irrelevant.

This, the academics argue, is exactly what an LLM does. It is not designed to represent the world or to track facts. It is a machine for generating plausible sequences of words. Its goal is to "sound normal," not to be correct. It is, by its very nature, a bullshitter.

This argument fits into the set of ideas I've been building here. It's a moral critique, and near its moral center is sincerity. They might say they really care about truth, not feelings like sincerity. But I'm not so sure. I think the moral outrage is tied to this idea of authenticity. It finds AI to be at fault because it lacks the right kind of intention, the intention to speak truthfully. This is part of what I've called ["Romantic Evil"](/post-9): a charge of inauthenticity, of "speaking words one does not inhabit."

It also echoes other critiques I've summarized:
- It's a form of **"frustrated ends" ([Post 11](/post-11))** because it performs the act of dialogue without the substance of a truth-seeking person, thus frustrating the natural end of conversation.
- It's an act of **"imitative negation" ([Post 12](/post-12))** because it is a "simulation without a subject," an output that looks like the work of a mind but lacks the presence of a mind that cares.

What makes this "bullshit" argument important is it gives a philosophical name to a common gut feeling. It comments on why interacting with AI can feel hollow. It's not just that the machine can be wrong; it's that it has no capacity to care about being right. Pure indifference is really alien to us humans.

This is a widespread moral argument against AI. But it's built on an assumption about what language is *for*. It assumes language is, or should be, a tool for sincere, truth-seeking humans. But what if that's not what language is for? More on that next.