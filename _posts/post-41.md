---
layout: post
title: "A Computational View of Language"
post_number: 41
---

The [last post](/post-40) explored the idea that AI is bullshit. It's a moral argument. It says the machine is a serious problem because it doesn't care about the truth. It's an empty, insincere imitation of a human speaker. This lines up with a lot of the [Romantic anxieties](/post-9) I've been tracking. But there's a competing view based on research into computation. The cognitive scientist Elan Barenholtz wants us to rethink the whole problem.

Barenholtz's starting point is that LLMs have given us a new empirically-based insight into the nature of language. He says the existence of LLM's go a long way to demonstrate that language is "autogenerative," a self-contained system with all the rules for its own operation baked into itself. It doesn't need to be connected to the real, physical world to function.

He explains it this way:
> What large language models show us is that words don't mean anything outside of themselves. As far as generation goes... is by stringing together sequences based on simply the learned relations between words.

This is a computational view. It sees language as a system of pure relations. An LLM learns the statistical patterns of how words connect to other words. It doesn't know what a "sunset" is, but it knows how the word "sunset" functions within the network of language. That's all it needs to write a paragraph about one. This is the same idea I was exploring in my posts on structuralism ([23](/post-23) and [24](/post-24)). Language is an autonomous system running on its own internal logic.

An implication of Barenholtz's argument is that if this is how language works, it might also be how we work. The part of our mind that handles language isn't some deep, authentic soul connected to experience. It's a specialized computational module that got "downloaded against your will."

This leads him to an uncomfortable place. The speaking self is separate from the feeling self.

> ...the thing doing the talking isn't the thing doing the feeling...seems almost like an out of Body Experience...I'm listening to myself talk right now who's actually forming these words

From this perspective, the "bullshit" critique is aiming at the wrong target. It accuses the machine of a moral failure (insincerity) when the machine is just revealing the amoral, computational nature of language itself. The hollowness we feel isn't the AI's failure to be a person; it's a glimpse into the impersonal language system that has been running inside us all along.

So, one view sees AI's indifference to truth as a moral flaw. The other sees it as a demonstration of how language works or what it is.