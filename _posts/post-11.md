---
layout: post
title: "Evil as Frustrated Ends"
post_number: 11
---

This is based on a [conversation from New Polity](https://www.youtube.com/watch?v=YuNJchmnMzI&t=3655s). Like with my last post, I start by explaining their general account of evil and then show how they apply it to AI.

### Definition
**Evil = privation of an act's natural end.** Human acts have built‑in purposes (*teloi*). Evil names designs and uses that elicit those acts while frustrating their ends. This is what makes vice. Chief example: conversation, whose end is communion with another person.

### Features
- **Simulacrum:** performing the form of an act (e.g., dialogue) without its substance (a someone who answers).
- **Asymmetry:** habituating one‑sided exposure without reciprocal responsibility or vulnerability.
- **Misalignment:** treating persons as means or as data; attenuating truth‑telling and promise‑keeping.
- **Deformation:** repeated frustrated acts reshape character toward cynicism, dependency, and untruth.

### Why AI Is Evil
- **Chat simulation:** chatbots elicit our conversational vulnerability while withholding real personhood. This frustrates communion.
- **Analogy to lying:** dialogue's form without interior truthfulness degrades the virtue of speech.
- **One‑way intimacy:** users reveal themselves; the system cannot do the same, yet retains their disclosures as "data."
- **Habit formation:** such use trains dispositions (toward flattery, passivity, and instrumental reason) at odds with honesty and love.

### Moral Center
Goodness is truthful conversation ordered to real communion. Giving from oneself to someone who can answer and be responsible.