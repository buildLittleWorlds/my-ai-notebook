<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Post 18 - My AI Notebook</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Space+Mono&display=swap" rel="stylesheet">
</head>
<body>
    <header>
        <h1>My AI Notebook</h1>
    </header>
    <main>
        <article>
            <h2>18 Propaganda and facts</h2>
            <p>The biggest and most obvious fear about AI is that it will fill the world with lies. That it will become a perfect machine for creating misinformation. But reading Ellul, this misses the point entirely.</p>
            <p>He argues the real danger isn't the lie. It's the fact.</p>
            
            <blockquote style="border-left: 3px solid #ccc; padding-left: 1.5rem; margin-left: 1rem; font-style: italic;">
                <p>A surfeit of data, far from permitting people to make judgments and form opinions, prevents them from doing so and actually paralyzes them. They are caught in a web of facts...</p>
            </blockquote>

            <p>This is the real trap. We think the problem is false information. So we work to build systems that deliver only true, correct, verifiable information. We think that if an AI can just give us the "facts," we will be free to make up our own minds.</p>
            <p>But Ellul says being buried in facts is what paralyzes us. An AI that can generate an endless stream of correct information doesn't set us free. It creates a complete world, a total "web of facts" we can't see beyond. The fight against misinformation will lead to a much more effective and invisible form of propaganda.</p>
            
            <p><a href="index.html">Back to Home</a></p>
        </article>
    </main>
    <footer>
        <p>&copy;2025 Daniel Plate</p>
    </footer>
</body>
</html>