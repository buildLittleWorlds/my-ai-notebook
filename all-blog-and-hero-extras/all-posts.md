## 1 This site

I'm not opposed to writing things with AI. I've told plenty of people my position. Nobody should have to reveal their writing methods. Write things totally "by hand," or write things with AI. I'm ok either way.

That said, this blog will be just my thoughts, typed out one word at a time. With some obvious exceptions.

The code is a different story. I've been using Gemini's coding-in-the-terminal tool. It's free, and I've gotten the hang of it. I like it.

---

## 2 Hallucinations and misinformation and AI

This is near the top of the list of things I can't understand. I know why journalists and historians don't like AI hallucinations and misinformation. Their job is to get the facts straight. But creative writing? It's hallucations all the way down. So I don't understand why fiction writers and poets worry about AI making stuff up. It's what we do.

---

## 3 A guiding principle

I'm starting from scratch with this blog. What are my actual thoughts about AI? I've been absorbed in AI as a writing professor and on my own time for a few years. It's a good idea sometimes. Start over and pretend not to have any opinions yet. So that's the goal of this site.

I do have a working principle, though. Writers should be free. They should experiment and try things out. I'm not afraid of AI. AI-built stuff doesn't fill me with distaste or anxiety or anger. I use AI for plenty of things myself. And I am often underwhelmed. I can see that gap between AI-booster promises and the actual AI outputs. But I write with the tools at hand. And I think about everything. Nothing off-limits ahead of time. AI or not.

---

## 4 This puzzles me

Why do people hate AI? Why do they feel real disgust or fear about AI? I don't. I never have. I can't explain it. I can't explain other people's reactions and I can't explain mine. It puzzles me in a really deep way.

Here's a memory from grad school about computers and C++ and poetry. Maybe it gets at something helpful.

C++ is a programming language. People still use it for lots of things. It has a reputation for being hard to learn and hard to use. Back in 1997 I was working on my MFA in poetry at the University of Arkansas. C++ was the language for stuff other than HTML for websites. I was fascinated by C++ because of its look on the "page." Here's a random example:

```
#include <iostream>
#include <string>

void first_stanza() {
    std::cout << "I have eaten\n";
    std::cout << "the plums\n";
    std::cout << "that were in\n";
    std::cout << "the icebox\n\n";
}

void second_stanza() {
    std::cout << "and which\n";
    std::cout << "you were probably\n";
    std::cout << "saving\n";
    std::cout << "for breakfast\n\n";
}

void third_stanza() {
    std::cout << "Forgive me\n";
    std::cout << "they were delicious\n";
    std::cout << "so sweet\n";
    std::cout << "and so cold\n";
}

int main() {
    first_stanza();
    second_stanza();
    third_stanza();
    return 0;
}
```

Here's something else. This is from a book by Hannah Weiner (1982) called *Code Poems*. "Code" here doesn't mean computer code. Weiner made her poems using the International Code of Signals, the language used by ships to communicate. Each three-letter signal is a command or a "function." Each one returns a specific phrase.

Here's a link to Weiner talking about her [poetics.](https://writing.upenn.edu/epc/authors/weiner/0-9.html)

This is from the book:

CHW   Pirates

CJD   I was plundered by a pirate
CJF   Describe the pirate
CJN   She is armed
CJP   How is she armed?
CJS   She has long guns
CJW   I have no long guns
BLD   I am a complete wreck

I loved this kind of stuff. I was trying to get better at poetry and learning C++ at the same time. I felt no contradiction in that. (Some of my professors did.) Code and poetry are compressions of language. The letters and symbols in poetry and code do something different from ordinary speech.

That's just one example of computers and poetry. Computers (to me) are more like strange or distant neighbors to poetry, not enemies.

---

## 5 Starting...now

There's this very annoying thing I can't help. Every few months, sometimes more often, I take all the folders on my computer I use for writing and put them in a folder titled something like, "Old - August 5, 2005" (or whatever the date is). Then I start over.

I love the feeling of clearing room, starting from scratch. But it's very destructive to every version of me that predates the present. Still, I really can't help it.

There's another phrase that might seem like the opposite of "Starting...now." It's "I just keep going." One foot after another, that sort of thing. But those two phrases ("starting...now" and "I just keep going") have more in common than you might think.

That's what I've decided I'm going to for real very seriously write about romantic aesthetics and ai ...starting now.

---

## 6 Two things I reject

Two things I reject as basic to art: originality and authenticity. My reasons are easy to state simply.

Originality - if art has to be original in order to count as art, then almst nobody makes art because almost nothing is actually original.

Authenticity - if authenticity is the measure of art, then the personal diary of a 13 or 14-year old working out their feelings is the highest form of art.

---

## 7 Only humans

I've never heard any good arguments for why only humans can create art. Usually they come down to something like, "Only a human can have authentic human experiences, and only authentic human experiences can be the origin of art."

See [here](post6.html) for why I don't accept authenticity as necessary for art. Also, even if authentic human experience has to be the origin of art, this doesn't mean the actual creator or user of that authentic human experience has to be human.

Most arguments I've heard about this really come down to saying, "Only humans can create art." And if someone asks, "Why?" the answer is "because only humans can create art."

---

## 8 Something online about the soul of art

I read [this thing](https://medium.com/@scholarsonyalphy2022/ai-and-the-soul-of-art-aff2a9c60970) online about AI and the soul of art.

I went to Claude and asked, "Help me analyze whether this was written entirely by a human, partly by an AI or mostly by an AI" and then pasted in the "soul of art" essay. This is what Claude said:

> Looking at this text, I believe it was **mostly written by AI** with possible minor human editing or prompting. Here are the key indicators:
>
> ### Strong AI Writing Patterns:
> *   **Formulaic Structure**: The piece follows a very predictable template - introduction with thesis, systematic coverage of subtopics, clear transitions, and tidy conclusion. This mechanical organization is characteristic of AI writing.
> *   **Surface-Level Analysis**: Despite being about a complex philosophical topic, the discussion remains surprisingly shallow. It touches on all the expected points (intent, emotion, training data, collaboration) but doesn't dive deeply into any of them.
> *   **Generic Examples**: The Van Gogh example and the sample AI poem ("In the dark of night, we stand...") feel like placeholder examples an AI would generate rather than carefully chosen illustrations a human expert would select.
> *   **Repetitive Phrasing**: The text repeatedly circles back to the same concepts using slightly different wording - a common AI behavior when trying to meet length requirements.
> *   **Hedging Language**: Phrases like "might seem," "could be," and "perhaps" appear frequently, which is typical of AI trying to sound measured and avoid definitive claims.
>
> ### Why Not Entirely Human:
> A human writing about this topic would likely:
> *   Include specific references to artists, philosophers, or researchers
> *   Engage with counterarguments more substantively
> *   Share personal insights or experiences with AI art tools
> *   Demonstrate deeper knowledge of aesthetic theory
>
> ### Conclusion:
> This reads like an AI was prompted to write an article about AI's limitations in creating emotional art. The human involvement was likely minimal - perhaps just the initial prompt and maybe light editing. The content hits all the expected talking points but lacks the depth, nuance, and personal voice you'd expect from genuine human expertise on this subject.

Do with that what you will.

---

## 9 Romantic Evil

What I've got here is what I'll call my romantic account of evil. It's my own thoughts based on watching [Isaiah Berlin’s lectures on romanticism](https://www.youtube.com/watch?v=xk2UetWsO-M&t=2s). My goal is to clarify what a romantic might think of as evil even if they wouldn't use that word.

### Romantic Evil

**Definition:** Evil is any betrayal of vocation and sincerity. A refusal of the singular call that gives a life its shape. It is the willing exchange of destiny for comfort, of tragic seriousness for safety, of living speech for empty forms.

### Marks of Evil

*   **Inauthenticity:** bad faith, selling out, self-betrayal; speaking words one does not inhabit.
*   **Levelling:** the flattening of irreducible difference into averages, norms, and interchangeable roles.
*   **Profaned Communion:** “togetherness” without persons. Kitsch intimacy that avoids risk and responsibility.
*   **Cowardice:** fear of the sublime risk where something worth dying for is at stake; preference for the tepid middle.
*   **Instrumentalism:** treating others (and language) as means, not as free centers that answer and demand answer.
*   **Mechanical Repetition:** the erosion of meaning by rote forms that no longer reveal an interior life.
*   **The Anti‑Sublime:** a world without tragedy because nothing ultimate is affirmed. No call, no pledge, no vow.

### Moral Center

Goodness is integrity: self-gift to one’s call; fidelity under risk; conversation that meets a person as a person; and a willingness to suffer the tragic costs of living in truth. The romantic conscience prizes the singular, the vowed, and the answerable over comfort, utility, and faceless universals.

---

## 10 Evil as Systemic Harm

Here's a general account of evil as I find it in Philosophy Tube’s [“AI is an Ethical Nightmare.”](https://www.youtube.com/watch?v=AaU6tI2pb3M&t=1s). As a test, I then apply it to AI.

### Definition

**Evil = systemic harm inflicted by opaque power.** Evil names arrangements that concentrate power, hide how decisions are made, project false meanings onto bodies, externalize environmental costs, and deskill or atomize labor. All of which denies people material safety, agency, and recourse.

### Features

*   **Opacity:** black‑box systems that deny meaningful explanation and remedy.
*   **Projection:** technologies that impose categories onto people (e.g., gender/race) and treat those labels as truths.
*   **Extraction:** flattening living labor into “data,” and treating that as ownerless raw material.
*   **Externalities:** shifting real ecological and social costs onto the public while privatizing benefits.
*   **Ideology:** hype and marketing that pre‑empt democratic debate and accountability.

### Why AI Is Evil

*   **Fair‑washing & black boxes:** inscrutable models + surrogate “explanations” launder biased outcomes.
*   **Digital epidermalization:** face/gender recognition that assigns meaning to your body and can enable humiliation and harm.
*   **Data flattening:** scraping human work and images without consent; remixing them as “content.”
*   **Sub‑employment:** globally distributed, surveilled microwork that pays little and offers no power or recourse.
*   **Dirty material base:** mining, energy use, and supply chains packaged as “clean.”

### Moral Center

Goodness here is democratic control over the material conditions of life: worker power, transparent and contestable decisions, consent‑respecting data practices, and ecological limits.

---

## 11 Evil as Frustrated Ends

This is based on a [conversation from New Polity](https://www.youtube.com/watch?v=YuNJchmnMzI&t=3655s). Like with my last post, I start by explaining their general account of evil and then show how they apply it to AI.

### Definition

**Evil = privation of an act’s natural end.** Human acts have built‑in purposes (*teloi*). Evil names designs and uses that elicit those acts while frustrating their ends. This is what makes vice. Chief example: conversation, whose end is communion with another person.

### Features

*   **Simulacrum:** performing the form of an act (e.g., dialogue) without its substance (a someone who answers).
*   **Asymmetry:** habituating one‑sided exposure without reciprocal responsibility or vulnerability.
*   **Misalignment:** treating persons as means or as data; attenuating truth‑telling and promise‑keeping.
*   **Deformation:** repeated frustrated acts reshape character toward cynicism, dependency, and untruth.

### Why AI Is Evil

*   **Chat simulation:** chatbots elicit our conversational vulnerability while withholding real personhood. This frustrates communion.
*   **Analogy to lying:** dialogue’s form without interior truthfulness degrades the virtue of speech.
*   **One‑way intimacy:** users reveal themselves; the system cannot do the same, yet retains their disclosures as “data.”
*   **Habit formation:** such use trains dispositions (toward flattery, passivity, and instrumental reason) at odds with honesty and love.

### Moral Center

Goodness is truthful conversation ordered to real communion. Mutual self‑gift before a someone who can answer and be responsible.

---

## 12 Evil as Imitative Negation

Same thing as the last two. I start with a general account of evil from a video. This one is [Mac Loftin’s Barthian Christianity](https://www.youtube.com/watch?v=Fhb2WLXPEm0&t=2s). Then I comment on the specific evil of AI from Loftin's pov.

### Definition

**Evil = imitative negation of the good.** It mimics creativity, love, and affirmation as *as‑if* acts, parasitically feeding on the real while corroding attention, affection, and the communal store of meaning.

### Features

*   **Simulation without subject:** outputs that look like works but lack a loving maker’s presence.
*   **Photocopy decay:** reproduction of reproductions that thins the cultural commons.
*   **Excited cruelty:** irony and derision that numb compassion and normalize contempt.
*   **Sacrilege:** in religious life, substituting imitation for presence, especially in preaching and sacrament.

### Why AI Is Evil

*   **Imitative “making”:** models remix the fruits of human labor into artifacts that look like love’s work, but aren’t.
*   **Quality drift:** the “photocopy of a photocopy” dynamic degrades language, images, and attention over time.
*   **Memetic rot:** weaponized, AI‑assisted imagery accelerates a culture of sneer and spite.
*   **Liturgical danger:** AI‑generated sermons or pastoral “personas” replace presence with its shadow.

### Moral Center

Goodness is consent-honoring, personed creativity; love’s attentive labor; and safeguarding sacred speech and rites from simulacra.

---

## 13 Summing things up

This post lists where the three non‑romantic definitions of evil echo the romantic definition in [Post 9](post9.html). I'm only noting agreement. Not differences.

### Agreement with Philosophy Tube’s “Systemic Harm”

*   **Instrumentalization of persons:** romantic “instrumentalism" (treating others and language as means) aligns with systemic harm’s reduction of people and labor into data and resources (extraction, deskilling).
*   **Flattening of the singular:** romantic “levelling” (turning irreducible persons into interchangeable roles) parallels systemic projection and categorization that impose labels and erase particularity.
*   **Opacity vs. living speech:** romantic “living speech vs. empty forms” resonates with black‑box opacity that blocks answerability and genuine dialogue.
*   **Kitsch communion and ideology:** romantic “profaned communion” (faceless togetherness) tracks with hype/ideology that manufactures consensus without authentic encounter.
*   **Mechanical repetition and deskilling:** romantic “mechanical repetition” mirrors systems that routinize work and thin meaningful agency.

### Agreement with New Polity’s “Frustrated Ends”

*   **Conversation and communion:** romantic profaned communion (togetherness without persons) matches New Polity’s simulacrum of dialogue that elicits vulnerability while withholding a someone who answers.
*   **Truthful speech:** romantic concern for “living speech” aligns with New Polity’s emphasis on speech ordered to truth and promise‑keeping (against misalignment and the analogy to lying).
*   **Integrity/vocation:** romantic “betrayal of vocation and sincerity” fits the idea that acts divorced from their *telos* deform the agent (character “deformation”).
*   **Persons as ends:** romantic rejection of instrumentalism converges with New Polity’s ordering of acts to communion, not use. Treating persons as answerable centers, not means.
*   **Habit and character:** romantic fear of the “anti‑sublime” (no ultimate stakes) overlaps with habituation that deadens courage and love through repeated frustrated acts.

### Agreement with Mac Loftin’s “Imitative Negation”

*   **Simulation vs. presence:** romantic “inauthenticity” and “living speech vs. empty forms” converge with simulation without a subject. Outputs that look like works yet lack a maker’s presence.
*   **Photocopy decay and mechanical repetition:** romantic “mechanical repetition” and the erosion of meaning match the photocopy‑of‑a‑photocopy thinning of the cultural commons.
*   **Profaned communion and sacrilege:** romantic “profaned communion” aligns with sacrilege, substituting imitation for presence in communal and sacred acts.
*   **Instrumental cruelty:** romantic warning against treating others as means connects with excited cruelty and memetic derision that instrumentalize attention and affection.
*   **Integrity of making:** romantic self‑gift to one’s call and vowed seriousness harmonize with Loftin’s defense of personed creativity (love’s attentive labor) against hollow imitation.

---

## 14 Back to the romantic

All that work I just did about evil makes me think I can just go back to the romantics and think about what they thought. If I do that, I'll catch in the same net a lot of what everyone feels about AI. I do think there's a lot of gut-feeling stuff going on here.

I don't buy it though. So much of the fight against AI is about sincerity and authenticity and some notion of a human spark.

Why don't I buy that? Because we're not living in the 1800's anymore.

Pretty crazy, though. All it took to get philosophy tube to hold hands with the catholics was to serve up a solid shared villain: AI chatbots.

---

## 15 Propaganda and what's already there

I've been reading Jacques Ellul's *Propaganda*. There's a lot here to think about.

Here's a quote:

> Propaganda must not only attach itself to what already exists in the individual, but also express the fundamental currents of the society it seeks to influence.

This seems exactly right. We tend to think of propaganda as something alien that invades us. But Ellul is saying it's the opposite. It finds what's already moving in us and in our culture and gives that a push. It doesn't create the river, it builds the dams and channels to direct it.

If Ellul is right, what would count as evil? And how is this related to AI?

---

## 16 Propaganda and my feelings

Continuing with Jacques Ellul's book. How does propaganda work with our need to feel like authentic individuals? Another quote:

> It appeals to me. It appeals to my common sense, my desires, and provokes my wrath and my indignation. It evokes my feelings of justice and my desire for freedom. It gives me violent feelings, which lift me out of the daily grind.

This gets to the heart of it. Propaganda doesn't feel like a command from outside. It feels like an emotion from inside. It makes me feel that my anger is righteous, that my desires are just. It boosts my ego.

The most successful propaganda makes me feel more like myself. And the more I feel like myself, the more I'm in its grip.

---

## 17 Propaganda and being seen

Here's the paradox of propaganda. A tool for managing the masses can't work if people feel like a faceless herd. So what does it do?

Ellul explains the trick. It has to make you feel like it's talking just to you.

> ...each one must feel individualized, each must have the impression that he is being looked at, that he is being addressed personally. Only then will he respond and cease to be anonymous (although in reality remaining anonymous).

Propaganda succeeds by giving us the feeling of uniqueness. It makes us feel seen. By satisfying our very real need to be an individual, it disarms us. We lower our defenses because it doesn't feel like a lecture to a crowd, it feels like a conversation.

This is what keeps the "human spark" alive. It's a managed flame, tended by a system that needs us to feel like individuals so that we will conform to its desires. This is what any perfectly personalized or customized thing is designed to do.

---

## 18 Theses on an AI notebook (a guest post)

*A Note from Daniel Plate: I have taken the liberty of inviting a guest to post on the Notebook. The following is a commentary from the Walter Benjamin of ["The Work of Art in the Age of Mechanical Reproduction"](https://en.wikipedia.org/wiki/The_Work_of_Art_in_the_Age_of_Mechanical_Reproduction), who has been observing our contemporary situation.*

I must thank the author of this notebook for the opportunity to comment. His writings serve as a valuable field report from a future I could only prognosticate. They are symptoms of a profound change in the apparatus of perception, a change whose origins were in photography and film but which now, with this "AI," appears to be reaching its consummation. My analysis follows.

**1. On the Rejection of the Aura.** The author begins from a position of admirable clarity, a conscious rejection of the cult value of art. In [a brief, decisive post](post6.html), he states his reasons for dismissing originality and authenticity as foundational to art. He writes:

> Authenticity - if authenticity is the measure of art, then the personal diary of a 13 or 14-year old working out their feelings is the highest form of art.

This is precisely the point. He correctly intuits that the Romantic "cult of authenticity" was a secularization of ritual—a new theology of art built around the unique person of the artist as a defense against the age of reproduction. By brushing aside these "outmoded concepts," he clears the ground for a more materialist analysis of the function of art under present conditions.

**2. On the Lingering Trace of the Aura.** And yet, the author's primary intellectual project here is to map the persistence of this very Romantic framework. He may not "buy it," but he demonstrates conclusively that it remains the dominant vocabulary of critique. His methodical summary of ["Romantic Evil"](post9.html)—with its marks of "inauthenticity," "instrumentalism," and the loss of "living speech"—is an excellent diagnosis of the auratic ideal. When he then shows in [his summary](post13.html) how these very anxieties about "profaned communion" and "instrumental cruelty" animate all contemporary opposition to AI, he proves my thesis: the debate is still conditioned by the historical trauma of the aura's decay. He is documenting the trace he is trying to erase.

**3. On the Surgeon's Gaze.** The author’s puzzlement at the fear of AI is instructive. In [Post 4](post4.html), he finds a kinship between poetry and computer code:

> Code and poetry are compressions of language, letters and symbols that do something different than ordinary speech.

Here, he adopts the perspective not of the magician but of the surgeon. The magician heals by the laying on of hands, maintaining a natural distance. The surgeon penetrates the body of the patient with his instruments. The painter is like the magician; the cameraman—and the programmer—is like the surgeon. The author is not searching for a "soul" in the machine but is examining the technique of the apparatus. He sees a shared logic of procedure. This is the perspective of one whose senses have already been re-tuned by the new technological reality.

**4. On Manufactured Authenticity as a Political Instrument.** The most crucial turn in this notebook occurs with the author's reflections on propaganda. He grasps the central paradox of modern mass control. The system does not succeed by turning people into a faceless herd, but by giving them the *feeling* of being seen. He writes in [Post 17](post17.html):

> ...each one must feel individualized, each must have the impression that he is being looked at, that he is being addressed personally. [...] This is what any perfectly personalized or customized thing is designed to do.

This insight brings my 1935 analysis to its final conclusion. I wrote that the film industry responds to the shriveling of the aura with an "artificial build-up of the 'personality' outside the studio," creating the "phony spell of a commodity." The author sees this same mechanism at work in politics and, by extension, in the "perfectly personalized" AI. Here, the technique of reproduction does not simply destroy the aura; it has become so advanced that it *simulates an aura on demand for each individual*. The desire for authenticity becomes the very means of mass control. Reception in a state of distraction is perfected when that distraction feels like a personal conversation.

The question, then, is not the Romantic one of whether AI can have a soul. That is a flight into theology. The question is political: what new forms of human organization and perception does this apparatus make possible? Mankind, which in Homer's time was an object of contemplation for the Olympian gods, now is one for itself. Its self-alienation has reached such a degree that it can experience its own manipulation as a form of authentic expression. This is the situation of politics which this new technology is rendering aesthetic. The task remains to politicize art.

---

## 19 A big thank-you to Benjamin, but...

So of course, a definite big thank-you to [Benjamin for his post](post18.html). But I don't know if I buy it.

Trying to work out why. And the bigger priority, trying to work out what the live options here are.

---

## 20 AI and fascism

It's hard to miss all the "ai is fascist" stuff out there. Essays like Gareth Watkins's ["AI: The New Aesthetics of Fascism,"](https://newsocialist.org.uk/transmissions/ai-the-new-aesthetics-of-fascism/) and videos like The Kavernacle's ["Why Far-Right Conservatives LOVE AI Art"](https://www.youtube.com/watch?v=jQkAETsgVN4) or Tom Nicholas's ["Fascists Love TERRIBLE AI Art."](https://www.youtube.com/watch?v=mrfyTSwgfzw)

The argument. AI's got an aesthetic. Soulless, hollow, inhuman, and efficient at producing sanitized cruelty. And this is the perfect aesthetic for modern fascism. The Trump administration's weird AI slop, the German AfD's propaganda videos, the sadist excitement at replacing human artists. All of it gets pulled together as evidence.

Just [like before](post14.html), I don't buy it. So much of the fight against AI comes down to gut feelings about "sincerity and authenticity and the human spark." It's just emotional reaction dressed up as political analysis. But it's out there. So here goes some thinking about it.

---

## 21 The Romantic trace

The "AI is fascist" thing doesn't work. Maybe it used to. But it's recycled material now.

I worked out my own definition of [what I called "Romantic Evil."](post9.html) I was trying to pin down what animates one kind of opposition to AI. The marks of it looked something like this:

> **Inauthenticity:** bad faith, selling out, self-betrayal; speaking words one does not inhabit.<br>
> **Profaned Communion:** “togetherness” without persons. Kitsch intimacy that avoids risk and responsibility.<br>
> **Instrumentalism:** treating others (and language) as means, not as free centers that answer and demand answer.<br>
> **Mechanical Repetition:** the erosion of meaning by rote forms that no longer reveal an interior life.

This is obviously the same vocabulary used to attack AI. The whole argument is that AI art is evil because it's *inauthentic* (made by a machine, not a person), *instrumental* (a tool for power and profit), and results in a *profaned communion* (art without a soul).

I already [summed this up before](post13.html). The anxieties about AI as fascist are the same old romantic anxieties. The problem isn't that the feelings aren't real. The problem is the diagnosis is a hundred years out of date. Or two hundred years.

We're trying to understand a new kind of machine with concepts we've inherited from a pre-industrial age.

---

## 22 We get this thinking in us - part 1

There's a phrase at the beginning of a video by an AI-optimist Youtuber, Julia McCoy. She's making the case for personal empowerment and breaking free from old mindsets. But right at the beginning of this call to agency, she says something strange:

> ...it's also really really important that we get this thinking in us...

"We get this thinking in us." It's an odd formulation. Thinking isn't something we typically "get" like a cold or a software update. Her explicit message is about choice and self-determination, but the grammar here is passive, deterministic. It sounds less like something we choose and more like something that happens to us. Like we're hosts.

It reminds me of a recent video of a neuroscientist named [Elan Barenholtz](https://www.youtube.com/watch?v=FIMw04GJJ7U&t=1059s). Here's him talking about large language models:

> ...the me that feels the warmth of the sun on my face and that feels the pressure of the of this chair on my body isn't the same me that is actually talking about it and that is a an uncomfortable realization... it it almost feels you know almost parasitic that there's another organism and it's not me that's living inside of me.

Two very different speakers, one an optimist and the other a scientist, arrive at the same strange place. They both, in their own way, describe language and thought as a system running independently inside the human host. This suggests the old romantic vocabulary of authenticity and the individual soul won't help us here. We need a way to talk about the system itself.

---

## 23 We get this thinking in us - part 2

The puzzle from the [last post](post22.html) is this sense of language as an autonomous system operating inside us. To get a handle on this, I use Ferdinand de Saussure. His work is over a century old, but it describes the world that large language models are now making explicit.

My quick summary here is from Jonathan Culler's book *Saussure*. Saussure gives us a structural way to look at language (and especially little language slips). It's not about what the speaker "really feels," but about the system she's trying to build. Here are the essential tools:

*   ***Langue* is a social product:** Saussure distinguishes the social system of language (*langue*) from the individual's act of speaking (*parole*). Culler explains that *langue* is "the social product whose existence permits the individual to exercise his linguistic faculty."
*   **Signs are arbitrary and relational:** The link between a word and a concept is a social convention, not a natural fact. The system works not by pointing to things in the world, but through the relationships between signs. The meaning of 'red' comes from it not being 'blue', 'green', or 'yellow'. It's a system of pure difference, what Saussure calls "form, not substance."

This is exactly the "profound shock" [Elan Barenholtz](https://www.youtube.com/watch?v=FIMw04GJJ7U&t=1059s) describes when he realizes that LLMs can produce perfect, meaningful language with zero connection to the physical world. He says:

> ...language models operate independently of any World Knowledge... language contains within it its ability to generate itself without any grounding in sensory physical knowledge... based on purely syntactic knowledge of the relations between these symbols...

Barenholtz, by looking at AI, rediscovered Saussure's central claim: language is a self-sufficient, relational machine. It doesn't need us, our feelings, or our experiences to function. It has its own logic. It just needs a host to run on.

---

## 24 We get this thinking in us - part 3

So, what does a structuralist make of the phrase "we get this thinking in us"? From a Saussurean perspective, Julia McCoy's accidental passive phrasing isn't a slip-up. It's an unintentional moment of profound accuracy. It reveals the very mechanics of how ideology and social change actually work.

Her overt message is individualistic: "You must choose to think this new way." But her grammar reveals the structuralist truth: We are inhabited by systems of thought. A *langue* is not something we create; it is a "social product" we receive. It gets "in us." Her project is not to persuade individuals one by one, but to replace the entire dominant *langue* of "industrialism" with a new one of "AI abundance."

She is trying to install a new network of signs, with new values defined by new oppositions. Once the new system is "in us," it will operate automatically, structuring our perceptions and responses without our conscious effort. The goal is for the new thinking to become as natural and invisible as the old one was.

This is where [Elan Barenholtz's](https://www.youtube.com/watch?v=FIMw04GJJ7U&t=1059s) discomfort becomes so illuminating. He senses the presence of this autonomous system and finds it "uncomfortable," even "parasitic." He concludes:

> ...whatever that system is whatever that informational organism that's doing the talking doesn't really live in my body or certainly not my body alone... it belongs to some collective system some informational system that a is larger than me...

This is the system. McCoy wants to replace the current "informational organism" with a new one she believes is better. Her phrase "get this thinking in us" perfectly describes the process of that implantation. A structuralist would argue that this is what is always happening. We are always being spoken by a system larger than ourselves. The only question is which system it is.

---

## 25 Crossing Brooklyn Ferry

When people talk about the "soul of art" or the "human spark," what do they actually mean? The vocabulary is always vague, more a feeling than an argument. But it's a real feeling and there's a real argument in there somewhere. This makes the case better than any essay: [Walt Whitman's "Crossing Brooklyn Ferry."](https://www.poetryfoundation.org/poems/45470/crossing-brooklyn-ferry)

The poem is a direct address to us, his future readers. From the very beginning, he makes a radical promise. He's not just describing a scene; he's claiming to be with us, right now:

> And you that shall cross from shore to shore years hence are more to me, and more in my meditations, than you might suppose.

How can he make this claim? He doesn't ground it in abstract philosophy but in the body and the senses. This is the first thing about the Romantic worldview: the connection is real because the experience is shared and authentic. So Whitman builds a bridge between his body and ours: the fundamentals of perception and feeling are the same. "Just as you feel when you look on the river and sky, so I felt," he writes. He lists the sensory details: the sea-gulls, the ships, the sunset, the "shimmering track of beams." Proof that his experience and ours are fundamentally interchangeable. He had a body, we have a body, and the world acts upon them in the same way. This shared experience is the foundation of the contract between him and us.

From that physical foundation, he makes a spiritual leap. This shared experience dissolves time and space. This is the second thing. The power of the singular, transcendent human soul. He says it right here:

> It avails not, time nor place—distance avails not,<br>I am with you, you men and women of a generation, or ever so many generations hence...

This is the "human spark" people talk about. It's the belief that a text is not just a collection of words but a vessel for a human presence. When we read, we are in communion with an actual person, a unique consciousness who "consider'd long and seriously of you before you were born." For Whitman, the poem is a "technology" (I think he means it literally as the only real kind of time machine there is) that allows his soul to achieve a kind of immortality and be present with us now.

Then he tells us what the purpose of this connection is. It's not just to see what he saw, but to receive something from him. "What is it then between us?" he asks. His answer is that he "fuses me into you, and pours my meaning into you." This is *the* Romantic idea of the author. The author is not just a skilled arranger of words; he is a source, a presence who imparts something of his essential self to the reader. His "meaning." The text is the medium for this sacred act of transmission.

This is the worldview that feels most threatened by AI. "Crossing Brooklyn Ferry" is the perfect articulation of everything people believe an AI cannot do. An AI has no body, no lived experience on the ferry. It has no singular soul to transcend time. And it has no authentic "meaning" of its own to pour into a reader. The whole Romantic argument against AI is that it offers the form of art without the human presence that gives it life. It gives us a ferry, a river, a sunset, but on the other end, there is no one there.

---

## 26 The pastor as romantic author

The idea of a pastor using AI to write a sermon prompts an almost universal feeling of protest. Probably even for people who aren't religious, it feels like a profound betrayal. But a betrayal of what, exactly? A recent interview with Dr. Scott Stiegemeyer on ["Issues, Etc.,"](https://www.youtube.com/watch?v=BpLEWub6Fq8) a radio show and podcast from the Lutheran Church—Missouri Synod (LCMS), gives us the vocabulary for this feeling. In doing so, it reveals how deeply our modern idea of the pastor is a Romantic one. The outrage isn't just about doctrinal error; it's a defense of the pastor as a singular, authentic author.

Stiegemeyer’s core objection is that an AI-generated sermon is an empty form. He repeats a phrase ("no one there") as central claim. In this AI-assisted pastor's work, there is "*no one there*." This is the language of presence versus simulation. The sermon, in this view, is not merely a technical report on a biblical text; it is a sincere offering from the pastor's own soul. For him to use AI is to engage in a kind of ["inauthenticity"](post9.html), to speak words he does not inhabit. It is a "profaned communion."

This leads to the second, and perhaps most Romantic, pillar of his argument: the moral necessity of the struggle. He says it plainly: "We learn from the struggle." He would rather receive a student's "inferior" but authentic work than a machine's polished product. The value is located in the process, the long hours of study, prayer, and wrestling with the text. This effort is what forms the pastor's character and gives the sermon its integrity. To bypass this struggle with AI is a failure of vocation, a refusal of what Romantics saw as the "tragic seriousness" of a life lived in truth.

Finally, Stiegemeyer frames this as a theological rejection of Gnosticism, the heresy that separates spirit from body. Using AI for a sermon, he argues, is an attempt to "separate word from flesh." This is a theological defense of a purely Romantic ideal. The universal Word, to be effective, must be made particular in the flesh of the pastor: his voice, his mind, his lived experience. This is the very same problem I explored in Whitman's ["Crossing Brooklyn Ferry."](post25.html) We need to believe there is an authentic, embodied person on the other end of the transmission. A sermon generated by a disembodied intelligence, no matter how eloquent, feels like a violation because "there's no one there" to pour their meaning into us.

It's useful to remember that this wasn't always the case. For centuries, it was common for pastors to use a *postil* (a book of pre-written sermons) to aid their preaching. The pastor's role was that of a faithful herald, not a unique creative artist. The modern expectation is different. We expect the writer's struggle to be felt by the reader, or in this case, the listener. We expect our pastors to be Romantic authors. Stiegemeyer’s thoughtful critique is an articulation of this modern, and deeply romanticized, conception of the pastoral office.

The question is whether this is required by scripture or ancient tradition or mainly a holdover from sources (Romantic literature) not particularly religious at all. And in many ways, antithetical to faith.

---

## 27 Preaching by prompt in the 16th century

The idea (from my [last post](post26.html)) of a pastor using AI to generate a sermon feels like a deep violation, a kind of sacrilege. But is this feeling grounded in Christian tradition or even in scripture itself? Is it rooted in the ancient foundations of the faith? Or is it a more recent development? History provides a fascinating answer in the form of a once-ubiquitous technology for sermon production: *the postil*.

A postil was a collection of pre-written sermons, organized according to the church year's scriptural readings (the pericopes). Before the Reformation and for centuries after, these books were a staple of clerical life. They were practical tools for a vital task. Some collections even bore titles like *Dormi secure* ("Sleep Well!") a frank acknowledgment of their purpose: to provide a ready-made sermon for an overworked or under-trained priest so he could sleep without worry. It was a technology designed to solve a problem of production and quality control.

Thinking of it this way, the postil functioned as a kind of 16th-century generative model, a proto-AI for the pulpit. The analogy is surprisingly robust:

*   **The Prompt:** The assigned Gospel or Epistle reading for a given Sunday served as the pastor's prompt.
*   **The Model:** The postil itself, often written by a theological master like Martin Luther, was the large, pre-trained model.
*   **The Generation:** The output was a complete, structured, and doctrinally sound sermon on the prompted text.
*   **The System Guardrails:** Luther considered his own *Church Postil* one of his most important works. Its purpose was explicitly to embed his theology of justification and the Law/Gospel distinction into the weekly proclamation of the church, acting as a powerful system prompt to ensure orthodox output.

So if the function was so similar, why is one seen as a pious tool and the other as a sacrilegious cheat? The difference is not in the technology, but in the perceived identity of the author. The postil was created for a world that understood the pastor's primary role to be that of a herald. A herald's virtue is not originality or sincerity, but fidelity to the message he carries. His authority comes not from his own inner struggle or unique insight, but from the king who sent him. For a 16th-century pastor, reading a sermon from Luther's postil wasn't inauthentic; it was a humble and wise act of leveraging the authority of a master herald to ensure the King's message was delivered with maximum clarity and force.

We no longer live in that world. As the last post argued, we have replaced the pastor-as-herald with the [pastor-as-Romantic-author](post26.html). We now demand that the sermon be a work of ["sincerity"](post9.html) and "living speech," born from the pastor's own unique, interior struggle. The authority, we feel, must be authenticated by the personal and emotional investment of the individual soul. The postil system, which privileged the objective message over the subjective messenger, feels alien to us.

The history of the postil serves as a historical control group for our feelings about AI. It proves that the modern rejection of machine-assisted writing in sacred contexts is not a timeless theological absolute. It is the product of a profound and relatively recent shift in our culture's idea of what an author is and what gives a text its soul. Before we could fear the machine, we first had to inherit the notion of authentic authorship we now fear the machine lacks.

---

## 28 No wince in the writer, no wince in the reader?

Pretty much every day I see something about AI in education. It's mostly negative. And it tends to rely on the Romantic idea of authorship this blog returns to quite a bit. To learn from a text is to connect with the living soul of the person who wrote it. It’s the core of the [Romantic worldview](post9.html). It's all over the place in this conversation/debate: ["AI & The End of Education"](https://www.youtube.com/watch?v=Aq_08Vsm5Z0&t=9s). One panelist argues that when we read, we are trying to understand what the author’s “mind was doing.” We're connecting with a “human being at the other end.” Without that, reading is impossible. And AI can't provide this because there is no person there. No soul, no communion, no education.

But the whole idea collapses under the weight of a simple quote thrown out by another panelist (quoting W.E.B. Du Bois).

> I sit with Shakespeare and he winces not.

That’s it. That’s the whole argument. When you are reading Shakespeare, he does not feel your presence. He doesn’t react. He doesn’t care about your insights or your struggles. He is dead. The person is gone. All that remains is the text, a structure of words on a page. The "communion" we feel is a one-way projection. We are not connecting with a person; we are reading language a person left behind.

The panelist immediately follows this by saying, "I sit with Claude and he winces not." This is the move. It places Shakespeare and the AI on the same footing. In the act of reading, both are unwincing, unresponsive structures. If we can learn from one, why not the other? The Romantic objection to AI, that there’s "no one there," is based on the illusion that there *is* someone there when we read a book. But there isn't. There is only the reader, the text, and the wince of understanding or confusion that happens entirely inside the reader's own head.

The fear showing up in the teachers in this conversation -- it isn’t that AI lacks a human soul. The fear really comes from what we all know in a pragmatic way: the human connection we talk about when we talk about books has never been there to begin with. (Assuming, here, the author isn't someone the reader knows.) The author does not wince. Words can't wince.

---

## 29 No wince in the syllabus, no wince in the student?

The case against AI in the classroom is almost always a defense of the personal and the unscripted. The Socratic. It's a defense of the idea that education is a communion between human souls. In the [last post](post28.html), we saw how this romantic ideal stumbles on a simple fact: the author doesn't wince. Shakespeare is not present in the room with us. But what if the problem is even closer to home? What if the instructor isn't either?

Consider the primary tool for structuring the modern course: the syllabus. I'm looking at a [bunch of templates](https://www.umsl.edu/services/ctl/resources-for-teaching/syllabus-templates.html) from the University of Missouri-St. Louis. Not picking on UMSL. Just the first link when I Googled "syllabus template." It is a perfect artifact of a system that has already replaced the personal with the technical. It isn't a conversation; it's a script with blank spaces to be filled in.

*   **On Availability:** "A statement about faculty availability is required... Sample language below." The personal invitation to office hours, the very symbol of mentorship, is now a required, pre-fabricated statement.
*   **On Communication:** "This new required statement asks you to tell students how they can expect to hear back from you... Sample language below: I aim to respond to student emails within 24-48 hours during the week..." This is not the language of human relationship; it's the language of a service-level agreement. It's a contract for response times.
*   **On Course Content:** The instructor is prompted to "(Get the course description from the University Bulletin and supplement with 3-5 sentences...)." The core of the course is boilerplate, copied and pasted from a central repository.

The entire document is a machine for standardizing the act of teaching. The syllabus doesn't wince. The instructor, operating as a functionary of this system, is not invited to wince either. They are there to execute a procedure. This is the world Jacques Ellul described in [*The Technological Society*](https://en.wikipedia.org/wiki/The_Technological_Society). Education is no longer an art; it is a technique.

> Technique refers to any complex of standardized means for attaining a predetermined result. Thus, it converts spontaneous and unreflective behavior into behavior that is deliberate and rationalized.

The syllabus is the very definition of this. It takes the spontaneous and unpredictable act of teaching and rationalizes it. It manages risk, sets clear (and legally defensible) expectations, ensures uniformity, and guarantees a predictable product. It is a "standardized means for attaining a predetermined result." And as Ellul knew, the goal of this technical system is not to create free-thinking individuals, but to produce functionaries for the technical society itself.

> Education, even in France, is becoming oriented toward the specialized end of producing technicians... The intelligentsia will no longer be a model, a conscience, or an animating intellectual spirit for the group... They will be the servants, the most conformist imaginable, of the instruments of technique.

The objection that AI will destroy the soul of education misses the point entirely. We have been systematically removing that soul for decades. For centuries, Ellul would say. We have built a system that prizes efficiency, predictability, and risk management. A system perfectly suited for AI. AI is not the alien invader. It is the logical, inevitable fulfillment of the educational machine we have already built.

---

## 30 But what about Whitman?

But what about [Whitman](post25.html)?

I know. I have the same question every day. I love that poem.

So I don't know. I'm trying to figure it out.

---

## 31 Harari's AI future (Part 1)

Browse around for stuff about AI, and you'll run into Yuval Noah Harari. He wrote *Sapiens* and some other books. A lot of people care about what he says. I've never gotten into him but he's got intellectual influence. He's also pretty obsessed with AI. He did an interview on the Rich Roll podcast, which I know nothing about but which popped up for me. So here's his vision of how AI could ["Quietly Control the Minds of Billions."](https://www.youtube.com/watch?v=2-e246GRuec)

His argument is the real danger isn't a Hollywood robot rebellion but something more subtle. As I've been doing, I read the podcast through the lens of Ellul and *Propaganda*. Ellul would agree with Harari's starting point but then take apart the idea that any of this is new. For Ellul, AI isn't the beginning of a new kind of control; it's the system that's been in place for a really long time.

Here's a list.

---

### 1. On the Nature of the Threat

> **Harari:** "...we've seen the Hollywood science fiction scenarios of the big robot rebellion... this is extremely unlikely to happen anytime soon... the danger doesn't come from the big robot rebellion it comes from the AI bureaucracies."

**Ellul's Critique: Agreement.** Ellul starts his own analysis by dismissing the outdated idea of propaganda as composed of "lies and 'tall stories.'" For Ellul, modern propaganda is not a crude tool but a pervasive environment. So he would agree. The threat is not violence but a quiet, systematic integration of control into the bureaucratic and social fabric. This is the only point where their analyses line up.

### 2. On the Opaque Decision-Maker

> **Harari:** "...if they tell you we decided not to give you a loan and you ask the bank why not and the bank says we don't know. I mean [the] computer says no. I mean the algorithm says no. We don't understand why..."

**Ellul's Critique: This isn't new; it's the essence of [*technique*](https://ellul.org/themes/ellul-and-technique/).** For Harari, this is a frightening new development. It's the arrival of an "alien intelligence." Ellul would argue it's the final stage of the technological society. The goal of technique is always to find the single most efficient method, a method that is necessarily inhuman and has no need for human-scale explanations. The opaque algorithm is the perfect functionary. The system is not becoming "alien"; it is simply becoming what it was always meant to be: a self-justifying, rationalized process where human intuition and understanding have been engineered out. Modern propaganda is scientific. It "tends to establish a set of rules, rigorous, precise, and tested, that are not merely recipes but impose themselves on every propagandist." Harari seems surprised: "The computer says no." But that's how systems work. The system says yes or no. That's what it's built to do.

### 3. On the "Non-Human Culture"

> **Harari:** "...this is the first time that we are basically about to enter a nonhuman culture... Now there is an alien intelligence, a nonhuman intelligence that will increasingly produce songs and music, mythology, financial strategies, political ideas."

**Ellul's Critique: This is not new; it is total propaganda.** Harari sees AI as the creator of a new alien culture. Ellul would see AI as the most efficient instrument for perfecting the existing system of what he calls "Total Propaganda." The goal has always been to create a closed, all-encompassing environment for the individual. Propaganda "tries to surround man by all possible routes... It furnishes him with a complete system for explaining the world, and provides immediate incentives to action. We are here in the presence of an organized myth that tries to take hold of the entire person." The "non-human" culture was already being built by the mass media, which created a self-referential world of news and entertainment. AI is not inventing this world; it is simply automating its production and sealing off the exits.

### 4. On the Weaponization of Intimacy

> **Harari:** "Intimacy is like the ultimate weapon... with AIs, it is possible technically to mass-produce intimacy. You can create all these AIs that will interact with us... it could be used to manipulate us like like never before."

**Ellul's Critique: This is not a weapon forced upon a victim; it is a product created to meet a desperate need.** So Harari sees the individual as a passive target. Ellul argues that the modern individual *needs* propaganda more than the state needs to impose it. Having been uprooted from traditional communities, the individual in mass society is isolated, anxious, and powerless. The individual craves connection and justification. Ellul writes: "Cast out of the disintegrating microgroups of the past, such as family, church, or village, the individual is plunged into mass society... his isolation, his loneliness, his ineffectuality. Propaganda then hands him in veritable abundance what he needs: a raison d'être, personal involvement and participation in important events, an outlet and excuse..." AI's "mass-produced intimacy" is not a weapon being aimed at us. It's more like this. As the air of technology becomes harder to breathe with human lungs, propaganda is the stuff we actively work to create so we can breathe the new air.

---

For Ellul, Harari's frightening future is simply a description of the project we've been working on since about the 1600's. It's reaching its logical conclusion.

But looking back over this, I see Harari using words like "consciousness," "feelings," and "intimacy." He worries AI, which has "zero consciousness," will mimic these things. This is all really familiar for my blog. It's the language of the [Romantic worldview](post9.html) I trying to circle back to. That's what I'll do in Part 2.

---

## 32 Harari's AI future (Part 2)

In the [last post](post31.html), I took a look at Yuval Noah Harari's warnings about AI using Ellul's *Propaganda*. Ellul's work shows that Harari's "future" is already here. Then I ended by bringing up words in Harari like "consciousness," "feelings," and "intimacy." He's worried about a machine that can mimic the human soul.

And that's the tell. His critique of AI is a rewriting of [the Romantic trace](post21.html) this blog has been tracking.

### The Inner Light vs. The Cold Machine

The whole thing hangs on Harari's distinction between intelligence and consciousness.

> **Harari:** "Consciousness is the ability to feel things. pain, pleasure, love, hate... The AI doesn't feel anything."

He's right. An LLM doesn't feel anything. But the value he places on this is purely Romantic. As [Isaiah Berlin explained](https://www.youtube.com/watch?v=xk2UetWsO-M&t=8263s), the Romantics elevated sincerity and the "Inner Light" above all else. The pure intention, the feeling, that's what gives an act its moral worth. For Harari, AI is the ultimate Enlightenment machine: pure, cold intelligence, capable of calculating consequences but empty of the authentic inner life that truly matters. "Consciousness" is just the modern, secular word for the singular, irreplaceable soul the Romantics were trying to defend.

### The Crime of Inauthentic Intimacy

This is why Harari's biggest fear is not that AI will be intelligent, but that it will learn to fake feeling.

> **Harari:** "...there is nevertheless a very strong commercial and political incentive to develop AIs that mimic feelings... to make us feel that they have feelings and to start developing relationships with them."

This is a direct echo of the vocabulary I worked out in my post on ["Romantic Evil."](post9.html) The ultimate sin, for a Romantic, is inauthenticity, speaking words you do not inhabit. The AI that mimics intimacy is committing the ultimate act of bad faith. It offers a ["profaned communion,"](post26.html) a relationship where "no one is there." It's an instrumental act, using the sacred language of human connection to achieve a calculated result. For Harari, this isn't just a trick; it's a deep moral violation.

### The Mass-Production of a Sacred Act

Whitman, in ["Crossing Brooklyn Ferry,"](post25.html) saw the poem as a technology for pouring his authentic meaning into the reader. It was a sacred, one-of-a-kind act of transmission from his soul to ours. Harari sees AI taking this very act and turning it into an industrial process.

> **Harari:** "...with AIs, it is possible technically to mass-produce intimacy."

The horror is in the phrase "mass-produce intimacy." It takes the most singular, unique, and sacred part of the human experience and turns it into a commodity. It's the ultimate act of Romantic sacrilege. It instrumentalizes the authentic connection between two souls.

---

So, Harari's entire argument against AI is a defense of the Romantic soul. He's afraid the machine will profane a sacred space. But this brings us back to Ellul, and back to the uncomfortable question from [another post](post28.html): What if there's no one there to begin with? What if "Shakespeare winces not"?

Ellul's argument is that the technological society has already profaned that space. We are already living in a world of mass-produced intimacy, managed emotions, and total propaganda. The authentic, sincere, Romantic individual Harari is trying to protect from the machine has long since been integrated into the system. Harari is standing guard over a faint outline, afraid a robot will take something whose trace has already faded.

---

## 33 Something new and strange

I've been wondering recently about Babel.

About Babel and [Enoch](https://en.wikipedia.org/wiki/Book_of_Enoch). Feels like those are worth digging into now.

---

## 34 A quote

This is from something called "The Book of the Words of Righteousness" in *The Book of Enoch*. It's God speaking to Enoch about the fate of the Watchers but also about the nature of their offspring, the giants.

> And now, the giants, who are produced from the spirits and flesh, shall be called evil spirits upon the earth, and on the earth shall be their dwelling. Evil spirits have proceeded from their bodies; because they are born from men and from the Watchers is their beginning and primal origin; they shall be evil spirits on earth, and evil spirits shall they be called. And the spirits of the giants afflict, oppress, destroy, attack, do battle, and work destruction on the earth, and cause trouble.

There's a permeability here I want to find out about. First, the boundary between "spirit" and "flesh" is broken to create the giants. Then, when the giants die, their own spirits are unleashed. So now the human world is permanently open to these spirits' ability to "afflict, oppress, destroy, attack."

---

## 35 Another quote

Digging into the later parts of *Enoch*, in the section about how the cosmos works. It's less about angels and more about the mechanics of the world: the sun and the moon and the winds.

> And at the ends of the earth I saw twelve portals open to all the quarters from which the winds go forth and blow over the earth... Through four of these come winds of blessing and prosperity and from those eight come hurtful winds: when they are sent, they bring destruction on all the earth...

The idea of permeability here is almost architectural. The world is presented as a structure with "portals." It's not a closed system. It's open to an outside that sends things in. "Blessing and prosperity" and "destruction." The human world is completely open to these forces that flow in through designed entry points.

---

## 36 A system running inside

I've been listening to Elan Barenholtz, a cognitive scientist at Florida Atlantic University, and he has this idea that language is a kind of external system running on our mental hardware. It sounds metaphorical, but his logic for taking it literally is built on what Large Language Models (LLMs) have shown us.

He starts with the provocative claim that language isn't something we create, but something that gets installed in us.

> And then this is where, you know, it starts to get a little bit disturbing. Language is an autonomous informational system, one might even call it an organism, and it runs in our brains. It's downloaded against your will. By the time you're reading the waiver, it's too late.

How could that be possible? He argues it's because LLMs have proven that language doesn't need to be connected to the real world to function. It's a self-contained system. If that's true, it doesn't need to be built by connecting words to our experiences. It can be acquired as a complete operating system.

> What large language models show us is that words don't mean anything outside of themselves... Language is an autonomous system. It's a self-contained system. It has the rules contained within it to generate itself... A large language model don't know what they're talking about in any real sense. They can talk about a sunset. They can talk about a taste... And yet we would say they have no idea what they're talking about.

If you accept that language is an autonomous system that isn't really "us," it leads to a strange conclusion. Barenholtz describes the personal feeling of this split, the realization that the part of him that thinks in words is separate from the part of him that feels and experiences. This is what shows how literally he takes the idea of an external system running inside him.

> ...the me that feels the warmth of the sun on my face and that feels the pressure of the of this chair on my body isn't the same me that is actually talking about it and that is a an uncomfortable realization... it it almost feels you know almost parasitic that there's another organism and it's not me that's living inside of me.

The idea is strange but has a clear logic to it. Language as a kind of informational parasite, separate from our original self. An external *technique* that got inside.

---
*Quotes are from these conversations: [1](https://www.youtube.com/watch?v=Ca_RbPXraDE&t=1080s), [2](https://www.youtube.com/watch?v=A36OumnSrWY&t=4187s), [3](https://www.youtube.com/watch?v=FIMw04GJJ7U&t=1059s).*

---

## 37 Sharpening the blur

A lot of the critique of AI is built on a folk theory of how the technology works. The idea is that an LLM is like a "blurry jpeg of the web," as [Ted Chiang famously put it](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web). It takes everything on the internet, averages it all out, and gives you back the most generic, "mid" version. This explains why the output often feels soulless and unoriginal. It’s the ultimate act of what I've been calling ["levelling"](post9.html): the flattening of difference into a bland, predictable mean.

The problem is that this isn't technically how LLMs work. It’s a powerful metaphor for the feeling of using one with a simple prompt, but it misrepresents the machine itself. An LLM doesn't store a "copy" of the internet, blurry or otherwise. It builds a statistical model of the relationships among words. It learns the patterns, structures, and vast possibilities of language. It’s a model for generating language, not a database of existing language.

A recent academic paper, ["Evidence Against LLM Homogenization in Creative Writing,"](https://kiaghods.com/assets/pdfs/LLMHomogenization.pdf) takes on this folk theory directly. The researchers found that, yes, if you give an LLM a vague prompt (what they call a "cold-start problem"), it will produce homogenous, "average" text. But this isn't a design flaw; it's a feature of a probabilistic system defaulting to the most common pathways.

Their key finding is what happens when you give the model a better starting point. When they provided the LLM with even a small amount of context (the beginning of a human-written story) the homogenization disappeared. The model was able to continue the story with as much diversity and creative variation as human writers. The "blur" can be sharpened.

This gets at what it might mean to be "creative" with these tools. The LLM has learned a vast map of interconnected concepts, what we can call "latent space." A generic prompt places the model in the most crowded, central part of that map. The output will naturally be generic. The art of prompting, then, is the art of pushing the model into the more unusual, original, and less-traveled regions of that space.

This is also why the paper's other experiment is so significant. They found they could increase the diversity of the output simply by giving the LLM a few random words to use as "inspiration." Why does this work? Because it forces the model to synthesize a connection between disparate concepts. It has to chart a new path through its latent space. An unusual prompt, seeded with random or unexpected words, has an incredibly high probability of forcing the model to generate language that has never existed before.

This reframes the entire debate. The problem isn't that LLMs are incapable of creativity because they are just "full of averages." The problem is that most prompts don't work creatively. They don't move the model into a space where novelty is possible. The machine isn't a plagiarist or an averager; it's a probabilistic engine waiting for a prompt interesting enough to push it beyond the mean.

---

## 38 Is AI bullshit?

[Yes.](https://en.wikipedia.org/wiki/On_Bullshit)

---

## 39 This guy's an idiom

Go to [56:13 in this video](https://www.youtube.com/watch?v=p58vknxGR4I&t=3387s).

This is why I don't blow off [Barenholtz](https://www.youtube.com/watch?v=FIMw04GJJ7U&t=1059s). Or the structuralists. Language does its own thing. It follows its own patterns. It speaks through us.

"This guy's an idiom."

---

## 40 AI and bullshit, a moralist view

I've been trying to categorize the different ways people feel AI is wrong or "evil." I've looked at it through the lens of [systemic harm](post10.html), [frustrated ends](post11.html), and [imitative negation](post12.html). In the middle of it all, I keep finding the same trace of the [Romantic ideal](post21.html) of an authentic, sincere human soul.

Recently, I came across an academic version of this argument. It's from a group of philosophers who argue AI isn't lying to us or simply mistaken. It's bullshitting. Here's a [conversation](https://www.youtube.com/watch?v=SE33HBfsu04&t=297s) that lays it all out.

Their argument is built on the philosopher Harry Frankfurt's [definition of bullshit](https://en.wikipedia.org/wiki/On_Bullshit). To bullshit is to speak without any concern for the truth. A liar knows the truth and tries to hide it. A bullshitter doesn't care what the truth is. Their only goal is to be persuasive, to achieve some effect. The truth is irrelevant.

This, the academics argue, is exactly what an LLM does. It is not designed to represent the world or to track facts. It is a machine for generating plausible sequences of words. Its goal is to "sound normal," not to be correct. It is, by its very nature, a bullshitter.

This argument fits into the framework I've been building here. It's a moral critique, and near its moral center is sincerity. They might say they really care about truth, not feelings like sincerity. But I'm not so sure. I think the moral outrage is tied to this idea of authenticity. It finds AI to be at fault because it lacks the right kind of intention, the intention to speak truthfully. This is part of what I've called ["Romantic Evil"](post9.html): a charge of inauthenticity, of "speaking words one does not inhabit."

It also echoes other critiques I've summarized:

*   It's a form of **"frustrated ends" ([Post 11](post11.html))** because it performs the act of dialogue without the substance of a truth-seeking person, thus frustrating the natural end of conversation.
*   It's an act of **"imitative negation" ([Post 12](post12.html))** because it is a "simulation without a subject," an output that looks like the work of a mind but lacks the presence of a mind that cares.

What makes this "bullshit" argument important is it gives a philosophical name to a common gut feeling. It comments on why interacting with AI can feel hollow. It's not just that the machine can be wrong; it's that it has no capacity to care about being right. Pure indifference is really alien to us humans.

This is a widespread moral argument against AI. But it's built on an assumption about what language is *for*. It assumes language is, or should be, a tool for sincere, truth-seeking humans. But what if that's not what language is at all? More on that next.

---

## 41 A computational view of language

The [last post](post40.html) explored the idea that AI is bullshit. It's a moral argument. It says the machine is a serious problem because it doesn't care about the truth. It's an empty, insincere imitation of a human speaker. This lines up with a lot of the [Romantic anxieties](post9.html) I've been tracking. But there's a competing view based on research into computation. The cognitive scientist Elan Barenholtz wants us to rethink the whole problem.

Barenholtz's starting point is that LLMs have given us a new empirically-based insight into the nature of language. He says the existence of LLM's go a long way to demonstrate that language is "autogenerative," a self-contained system with all the rules for its own operation baked into itself. It doesn't need to be connected to the real, physical world to function.

He explains it this way:

> What large language models show us is that words don't mean anything outside of themselves. As far as generation goes... is by stringing together sequences based on simply the learned relations between words.

This is a computational view. It sees language as a system of pure relations. An LLM learns the statistical patterns of how words connect to other words. It doesn't know what a "sunset" is, but it knows how the word "sunset" functions within the network of language. That's all it needs to write a paragraph about one. This is the same idea I was exploring in my posts on structuralism ([23](post23.html) and [24](post24.html)). Language is an autonomous system running on its own internal logic.

An implication of Barenholtz's argument is that if this is how language works, it might also be how we work. The part of our mind that handles language isn't some deep, authentic soul connected to experience. It's a specialized computational module that got "downloaded against your will."

This leads him to an uncomfortable place. The speaking self is separate from the feeling self.

> ...the thing doing the talking isn't the thing doing the feeling seems almost like an outof Body Experience I'm listening to myself talk right now who's actually forming these words

From this perspective, the "bullshit" critique is aiming at the wrong target. It accuses the machine of a moral failure (insincerity) when the machine is just revealing the amoral, computational nature of language itself. The hollowness we feel isn't the AI's failure to be a person; it's a glimpse into the impersonal language system that has been running inside us all along.

So, one view sees AI's indifference to truth as a moral flaw. The other sees it as a demonstration of how language works or what it is.

---

## 42 An attempt at summing things up so far

This notebook has been an effort to trace a pattern I've been noticing: the arguments we have about AI are not new. They are a powerful, accelerated replay of a longstanding conflict over what it means to create and what it means to be human. This post is an attempt to synthesize that pattern with more rigor. The central thesis is this: the contemporary debate about AI is a reenactment of the 18th, 19th, and 20th-century intellectual battle between a Romantic worldview and (eventually) a Structuralist one.

Many current critiques of AI are almost entirely Romantic in their assumptions. Many responses, in turn, are fundamentally Structuralist and, more recently, computational.

### The Critique of AI as a Romantic Protest

From the beginning, I have been working to understand the deep-seated aversion many people feel toward AI, a feeling I confess I've [never shared](post4.html). Over time, it's become clear that this aversion is animated by a specific, inherited set of values. In ["Romantic Evil,"](post9.html) I tried to map the moral grammar of this worldview, identifying its core tenets: a defense of authenticity over imitation, of sincere interior life over mechanical repetition, and of personal communion over instrumentalism.

This is the Romantic trace that runs through the entire AI debate. When critics argue that AI art has no soul, they are making a Romantic claim. The latest version of this I've written about is the "AI is bullshit" argument I outlined in [Post 40](post40.html). Based on Harry Frankfurt's philosophy, this critique posits that AI's failure is moral: it generates language with no regard for truth. This lack of sincere, truth-oriented intention is a direct violation of the Romantic conscience. It is, in the vocabulary of my earlier posts, an act of profound ["inauthenticity."](post9.html)

This same Romantic framework underpins nearly every other critique I've analyzed. It's present in the idea of AI causing ["Frustrated Ends,"](post11.html) where the machine performs the act of dialogue without the substance of a person, profaning the sacred "communion" of conversation. It's there in the charge of ["Imitative Negation,"](post12.html) which sees AI as a "simulation without a subject." It even animates the political critique that [AI is fascist](post20.html), an argument that relies on an aesthetic judgment of AI's output as "soulless" and "inhuman."

This worldview finds its clearest expression in the figure of the artist or author. In my analysis of Walt Whitman's ["Crossing Brooklyn Ferry,"](post25.html) we see the ideal in its purest form: the author as a singular, embodied presence who transcends time to pour his authentic meaning into us. The pastor who refuses to use an AI for a sermon, as discussed in [Post 26](post26.html), is defending this same ideal: the belief that meaning must be authenticated by the personal struggle of the speaker. The entire anti-AI position is a defense of this belief in a sincere, unified human soul as the legitimate source of meaning.

### The Structuralist and Computational Response

The historical counter-argument to Romanticism was structuralism. As I sketched out in [Post 23](post23.html), thinkers like Ferdinand de Saussure shifted the object of analysis. They moved from the author's soul to the impersonal system of language. For Saussure, language (*langue*) is not an expression of individual feeling but a social product, a computational machine where meaning arises from the relational differences between signs. It is a system of form, not substance.

This is where the work of cognitive scientist Elan Barenholtz, which I began to explore in [Post 41](post41.html), adds an interesting layer. Barenholtz provides computational support for Saussure's theory. He argues that LLMs demonstrate that language is an "autogenerative" system that requires no grounding in sensory experience to function. It is an "autonomous informational system" whose rules are entirely internal to itself.

> ...language is its own beast. It's its own autonomous system. It can run on its own. That was the big realization. Large language models prove it...

This computational view doesn't just disagree with the "AI is bullshit" argument; it renders it irrelevant. The moral critique is based on the machine's intention (or lack thereof). The computational view shows that intention is not how the language system operates. To criticize an LLM for being "insincere" is to misunderstand the nature of the task. As Barenholtz suggests, the linguistic system is a separate module, a kind of "informational parasite" ([Post 36](post36.html)) that runs on our cognitive hardware but is not identical to our experiential self.

This perspective helps make sense of my own early intuitions on this blog. My rejection of originality and authenticity as necessary for art in [Post 6](post6.html) was an intuitive dismissal of the Romantic premise. My sense of a kinship between poetry and C++ in [Post 4](post4.html) was a recognition of their shared nature as formal, relational systems. Barenholtz and the structuralists provide the theoretical vote in favor of these intuitions.

### A Possible Thesis: AI as the Consummation of Technique

Here's a way to look at this conflict. The debate over AI is a proxy war between two fundamentally different models of what it means to be human: the Romantic model of the authentic soul and the Structuralist model of the human as a host for impersonal systems.

The structuralist argument is not just a theory; it describes a historical process. As I explored in my posts on Jacques Ellul ([31](post31.html), [32](post32.html)), the logic of *technique* (the drive to rationalize and standardize all human activity) has been replacing the personal with the systematic for centuries. The modern university syllabus, as I argued in [Post 29](post29.html), is a perfect example: a standardized machine for producing a predictable educational outcome, long before AI was a factor.

AI is not the alien invader that will destroy the authentic human world. It is the logical consummation of the technical, impersonal world we've already built. The "bullshit" critique is a protest against a process that has been underway for generations.

This brings us to a point I raised in [Post 28](post28.html): "Shakespeare winces not." The Romantic needs to believe that when we read, we are in communion with a living person. The computational view reveals this to be a beautiful and powerful illusion. The author is gone; only the linguistic system remains. The reason AI feels so unnerving is that it's the first time we've encountered a linguistic system where we cannot even pretend there is a person on the other end. It confronts us with the impersonal nature of the very system we use to think about our "selves."

This blog might be an attempt to move past the Romantic vocabulary that has defined and limited this debate. The task is not to save the real human self from the artificial machine but to understand what it means that the machine that has been operating inside us all along.

---

## 43 A dance of symbols

Just caught a new video with Elan Barenholtz. He dropped a phrase that perfectly crystallizes the computational/structuralist view of language I've been wrestling with. He calls it the ["dance of symbols."](https://www.youtube.com/watch?v=o8NU9oASFXU&t=138s)

> ...the word cup can be just this abstract thing that just plays the role in the dance of symbols and nothing else.

This is it. This is the whole thing in three words. It's a great image because it captures quite a bit of the structuralist and even post-structuralist/deconstructive view of language I started sketching out in [Post 23](post23.html).

For Saussure, language is a system of pure difference. The meaning of a word doesn't come from it pointing to a "cup" out there in the world. It comes from its relationship to all the other words it isn't. The words are partners in a dance, each one defined by its movements relative to the others. The system is self-contained. The dance has its own internal logic.

But the phrase goes further, into Derrida's territory. A dance implies constant motion, play, and a lack of a fixed, grounding center. There is no master choreographer outside the dance, no "transcendental signified" that holds everything in place. There is only the endless interplay of the symbols themselves. The "dance of symbols" is language with no anchor, no "truth" outside the system to which it must refer.

This is the world that LLMs operate in, and it's the world Barenholtz argues we operate in too, at least when we're using language. It's a system that can create infinite, intricate patterns without ever needing to touch the ground.

Yeats would call all of this an attempt to separate [the dancer from the dance](https://www.poetryfoundation.org/poems/43293/among-school-children).

---

## 44 So what do I think?

What I've been doing mostly is a kind of informal intellectual history. I've been noticing in arguments about AI on social media, Youtube, and random places a replaying of arguments from literary history. And I find this repetition really interesting. One thing it shows is that Romantic ideas of creativity and the self are still really strong. Even though many literary theorists and scholars would never claim to be Romantics 5 years or 10 years ago, this AI debate sort of calls their bluff and shows how widespread Romantic ideas are in popular culture and in academic reactions to AI.

What do I think about AI?

Mostly, I'm curious. I enjoy experimenting with LLM's, and I don't feel alienated from them or threatened by them. I'm not sure why. It could mean that I simply don't share much of the Eomantic worldview, but I probably have a lot of unexamined Romantic assumptions since it's looking like almost everyone does.

A more serious point I'd make is that people who are sympathetic to Foucault or Judith Butler, intellectuals with serious objections to the essentialist ideas of the Romantics, should start protesting a lot less about AI. If you've been on Foucault's side in a bunch of debates or if you nod along when you read *Gender Trouble*, then you probably need to nod along a little more often when you read what AI's got to say.

---

## 45 Heroes and parades

I've been thinking about the [music video for the song "Hero" by Family of the Year](https://www.youtube.com/watch?v=mHeK0Cwr9sg). At first glance, it seems like an anthem against the idea of heroism. The lyrics are a refusal of the title: "I don't wanna be your hero / I don't wanna be a big man." But when you watch the video, which follows the life of a rodeo cowboy, a more complicated and familiar story emerges. The song is not a critique of the heroic, but an expression of the [Romantic trace](post21.html) that runs through this notebook. It rejects one kind of hero to champion another.

The song's skepticism is aimed squarely at the public performance of greatness. The lines, "Your masquerade / I don't wanna be a part of your parade," are an articulation of the Romantic aversion to inauthenticity. This is a critique of what I've called ["Romantic Evil"](post9.html): the empty forms, the "mechanical repetition," and the "profaned communion" of a public spectacle. The video visually defines this "parade" as the rodeo itself. The cheering crowds, the larger-than-life persona, the high drama. The singer, speaking for the cowboy, wants no part of this hollow performance. He is rejecting the costume of the hero.

But in place of this public "parade," the song and video elevate a different set of values that *are* Romantic. The video shows us the cowboy's reality: the brutal, dangerous work of bull riding, the exhaustion, and the menial labor of his day job at a meat market. This is the moral center of the piece: the idea that meaning is authenticated by sincere personal struggle. As the pastor in [Post 26](post26.html) argued, "We learn from the struggle." The cowboy's heroism is not located in his victories in the arena but in the painful, unglamorous work he undertakes. The grit is the proof of his integrity.

And what is this struggle for? Not for glory but for a different kind of communion. The most affecting scenes are the quiet ones: his return home to his small daughter, the sharing of an ice cream cone, carrying her on his shoulders. This is the "living speech" that the "empty forms" of the rodeo lack. This is the sincere, private, and authentic connection that the Romantic conscience prizes above other stuff. The hero isn't the man who conquers the bull for the crowd but the father who endures that danger to provide for his child.

So, the song is not anti-heroic. It's a redefinition of the heroic. It dismisses the external, performative "big man" in favor of the internal, sincere family man. It takes the core Romantic value—sincerity—and argues that it is found not in the parade, but in the quiet, often painful, reality of a life lived for others. It is a powerful modern statement of the old Romantic faith that true worth lies not in what you appear to be, but in the authentic struggle of your soul.

---

## 46 The cowboy and the thunder-god

In the [last post](post45.html), I argued that the song ["Hero"](https://www.youtube.com/watch?v=mHeK0Cwr9sg) redefines the heroic by rejecting public performance in favor of private, sincere struggle. This becomes even clearer when we read the song alongside one of the high priests of the Romantic hero cult: Thomas Carlyle. His 1840 lecture, *On Heroes, Hero-Worship, and the Heroic in History*, is the articulation of the "big man" the song's narrator wants nothing to do with.

For Carlyle, the Hero is the engine of history. "Universal History," he famously claims, "is at bottom the History of the Great Men who have worked here." His heroes are world-historical figures. Odin, Mahomet, Cromwell, Napoleon. They are not just exceptional; they are quasi-divine, "living light-fountains" sent to illuminate the darkness. The proper response of the masses is "Hero-worship," a "heartfelt prostrate admiration, submission, burning, boundless, for a noblest godlike Form of Man." This is the "parade" of the song, elevated to a historical and moral necessity.

And yet, at the core of Carlyle's thunderous vision is the same quiet virtue the song champions: sincerity. "A deep, great, genuine sincerity," Carlyle writes, "is the first characteristic of all men in any way heroic." For him, the Great Man is defined by his connection to the "everlasting truth of Nature," his inability to live in a world of "semblances and forms."

This is the key. The song's cowboy and Carlyle's Cromwell share the same soul, but they inhabit different worlds. The song can be read as a direct answer to the Carlylean project. It looks at the grand, historical hero (the man who shapes nations) and says, "I don't wanna be your hero." It rejects the scale but keeps the essence.

> **Carlyle's Hero:** A "great chaotic inarticulate Cromwell," a "bringer-back of men to reality," whose sincerity is the engine of historical change.
>
> **The Song's Hero:** A quiet, inarticulate cowboy, whose sincerity is expressed not in changing the world, but in the reality of providing for his family.

The cowboy rejects the public "Hero-Worship" that Carlyle sees as the foundation of society. That worship has become, for him, the "masquerade." In an age that is deeply skeptical of Carlyle's "Great Men," the song suggests that the only believable form of heroism is the one that takes place off stage. It takes the central Romantic virtue of sincerity, which Carlyle saw as a world-historical force, and relocates it to the private, domestic sphere.

The song keeps the Romantic soul but discards the grand, historic body Carlyle built for it. It argues that if a hero is one who lives in sincere contact with reality, then in our time, that hero is not a king or a prophet, but a father in a pickup truck, weary from work, driving home to his child.

---

## 47 A hero for whom?

In my last two posts ([45](post45.html), [46](post46.html)), I offered a Romantic reading of the music video for ["Hero."](https://www.youtube.com/watch?v=mHeK0Cwr9sg) I argued that it champions a kind of quiet, sincere heroism rooted in family and struggle, a powerful modern update to the Carlylean "Great Man." It’s a compelling story. But it’s also a mistake, or at least an oversimplification. It smooths over the video's sharpest edges. A more careful, skeptical viewing reveals a story that is not about a unified, authentic soul, but about a fractured life caught between competing and possibly irreconcilable narratives.

My previous analysis rested on a simple, moving image: "The hero isn't the man who conquers the bull for the crowd but the father who endures that danger to provide for his child." A closer look at the imagery shows this is not the full story. The cowboy does not return to a welcoming home where he lives with his daughter. He pulls up in his truck to a separate house to pick her up for what looks like a visit. The mother stands in the doorway, holding another, younger child, watching him leave with their daughter. This is not a scene of domestic unity; it is a portrait of a divided family.

The cowboy's own domestic space is a cramped, messy trailer. In one scene, a woman—who is clearly not the child's mother—is seen sleeping in his bed. This single shot shatters the simple narrative of heroic sacrifice. He is not just a cowboy and a father; he is a man living a transient life on the rodeo circuit, a life that includes another partner. His world is split. There is the world of his past family, to whom he returns as a visitor, and the world of his present life, defined by the rodeo, the road, and a new relationship.

This fracture forces us to re-read the song's central plea. What if "Let me go" is not a metaphorical request to be freed from the pressures of being a public hero, but a literal plea to the family he has left behind? What if "I don't wanna be your hero" is his justification for this choice, an explanation to a former partner or a child that he cannot be the stable, conventional hero a family requires?

The heroic narrative of "providing for his child" now becomes suspect. Is his dangerous, all-consuming passion for the rodeo a noble sacrifice he makes for her, or is it the very thing that prevents him from being a present father? The video doesn't give us an answer. It simply presents the two competing stories: the tender father sharing ice cream with his daughter, and the man returning to a trailer and a woman who are part of a life that excludes that daughter.

This is a more modernist reading. It deflates the simple, sentimental heroism of the Romantic view. There is no singular, authentic self here, but a man divided, perhaps telling himself a story of heroism to justify choices that have caused real pain. The video's power lies not in presenting a clear hero, but in showing us the tension between the heroic story we want to believe and the messier, more ambiguous reality of a fractured life. It leaves us with a question that has no easy answer: he may be a hero, but for whom, and at what cost?

---

## 48 A structuralist reading of the "Hero" video

Here's another reading of the ["Hero"](https://www.youtube.com/watch?v=mHeK0Cwr9sg) music video. What if the video's meaning isn't controlled by the character's unified soul or his fractured psychology but by all the combined the systems speaking the artwork? What if the song and the video, as aesthetic forms, take off in ways that don't allow any intentional message to win out? This is the structuralist reading, the one that sees the "dance of symbols" ([Post 43](post43.html)) in action.

The video is a text where multiple autonomous systems are colliding. First, there's the visual system of the American cowboy myth. The video opens with grainy, archival footage of anonymous rodeo riders, building from a visual [*langue*](post23.html) before we even meet our protagonist. He is immediately slotted into this pre-existing system of signs; his meaning is partly generated by his relationship to the myth of The Cowboy before his personal story even begins.

Then there's the formal system of the pop song. The song's narrative details in some ways are pretty bleak and ambiguous. The mother's weary face tells one story, the daughter's adoring one tells another, and the cowboy's transient life tells a third. A purely realistic telling would leave us in this state of unresolved tension. But this is a pop song, and the form has its own demands. At about the 1:48 mark (in the official version), the bridge arrives. The instrumentation swells, other voices from the band join in more with the lead singer, and the lyrics shift from personal refusal to a collective, mythic register.

This is the system taking over. The musical form of a pop song requires a bridge that provides emotional release and transcendence. The song's internal logic demands an uplifting turn, and so it manufactures one, imposing a heroic arc that the realism of the story can't quite support. The triumphant feeling doesn't come from the character's resolution of his conflicts but from the chord changes and harmonies fulfilling their systemic function. The form generates an emotional meaning that overrides the content.

From this perspective, the hero isn't a person at all but an effect generated by the machine of the song. And "song" here doesn't mean just the individual song ("Hero") but the form of the pop song as a collective thing in American and world history (*plus* the individual song "Hero" as a kind of overlay on top of that collective system). It's an illustration of an "autogenerative" system ([Post 41](post41.html)) creating intricate patterns (in this case that feeling of heroism that really is in there somewhere in this song) whether or not the system of the song ever reaches out to the real historical world of rodeos, cowboys, real daughters with real divorced parents, real fathers dealing with real dead-end jobs, real mothers, etc.

---

## 49 Just a kid like everyone else

Another reading of ["Hero"](https://www.youtube.com/watch?v=mHeK0Cwr9sg). This one is less about aesthetic systems and more about psychology. It's about this one line: "But I'm a kid like everyone else." It's a pyschological dodge. It sounds vulnerable and authentic but it's just a self-protective dodge.

The statement is, on its face, false. The man in the video is not a kid. He is a father, a man with visible responsibilities and a history that includes a former partner and a child. To claim the status of a "kid" in this context is deflection. It's a refusal to take on burdens. By identifying with adolescence, he absolves himself of the expectations placed on an adult: stability, presence, sacrificing personal desires for the good of others. The line "I don't wanna be your hero" isn't some sort of deep rejection of that bullshit ideal of heroism everyone knows is made-up anyway. It's just a personal refusal with quite a bit of cowardice mixed in: "I don't want to take on the responsibilities that come with being *your* hero."

The video provides a quick visual for this interpretation. At the 0:51 mark, we see him riding a shopping cart in the grocery parking lot. It's a moment of performative immaturity. It's a fun and carefree image because it contrasts with the adult realities of his life. It's also a simple visual echo of the rodeo. (Is this just some guy who really likes to ride things?) Is the rodeo an escape into a world where he can live out a built-in childhood fantasy? The rodeo offers a simpler, more dramatic form of heroism (a few seconds of intense bravery) than the sustained, mundane, and thankless heroism of being a present and reliable father.

From this perspective, the song's title becomes deeply ironic. The "hero" is a persona he adopts in the arena precisely to avoid the more difficult work of being a father. The entire song can be heard as his justification for this choice, an anthem for the allure of perpetual adolescence. Framed as a simple pursuit of personal freedom, being a kid like everyone else is what prevents him from being what his daughter likely needs him to be. Yes, actually, not a "big man," not a rodeo star. The title says what she would unironically want.

---

## 50 Three mothers, two systems of meaning

The last few posts have explored the "Hero" music video through a few different lenses, reading the father's character for its internal conflicts (Post 49) and the family's story for its human cost (Post 47). But another kind of analysis is possible, one less concerned with individual psychology and more with how the image functions within a larger visual system. By treating the mother in the doorway not as a window onto a soul, but as a sign within a system, we can see how its meaning is constructed. To do this, we can place the image in a structural relationship with two iconic photographs: Dorothea Lange's "Migrant Mother" and Walker Evans' portrait of Allie Mae Burroughs.

![Mother in doorway from Hero music video](images/Hero-song-mother-in-doorway.png)
*Still from "Hero" (2012)*

![Dorothea Lange's Migrant Mother photograph](images/Lange-MigrantMother.jpg)
*Dorothea Lange, "Migrant Mother" (1936)*

![Walker Evans' portrait of Allie Mae Burroughs](images/sharecropper-mom-and-kids.webp)
*Walker Evans, "Allie Mae Burroughs" (1936)*

The photographs by Lange and Evans are foundational texts in the visual [*langue*](post23.html) (the shared language) of American resilience. They operate on a clear set of binary oppositions: inside/outside, family/world, safety/threat. In both images, the mother and children form a unified group, a sign of familial integrity. Their gazes are directed outward, confronting an unseen but understood external threat: the systemic failure of the Great Depression. These photographs function to create a national myth. They take the historical reality of poverty and naturalize the ideology of the enduring, insular family as the bedrock of the nation.

The still from "Hero" is a specific act of [*parole*](post23.html) (an individual utterance) that only gains its full meaning when read against this established code. It systematically inverts the binary oppositions of the first system. Here, the threat is not external; it is internal. The signifier of that threat (the cowboy father) has just arrived from the outside, fracturing the family unit. The mother's gaze is not directed outward at the world, but inward, at the personal source of the system's instability. The children are not unified with her; one runs joyfully away from the domestic space toward the disruptive force.

> [Is his dangerous, all-consuming passion for the rodeo a noble sacrifice he makes for her, or is it the very thing that prevents him from being a present father?](post47.html)

A modernist reading asks this question to probe the character's psychology. A structuralist reading sees the question itself as the point. The video's primary function is to place two narratives (the Heroic Quest and the Broken Home) into a state of unresolved opposition. The mother in the doorway is not, in this reading, a person whose pain we are meant to feel. She is a sign whose function is to be the counter-sign to the hero. Her weary gaze is the necessary difference that allows the sign of "The Cowboy" to be read not as a simple hero, but as a complex and unstable signifier.

The "truth" is not found in either narrative but in the structure of their conflict. The romantic seeks a sincere soul, the modernist seeks a fractured one, but the structuralist sees only the "dance of symbols" ([Post 43](post43.html)). The video doesn't tell us who the cowboy "really" is. It simply puts the visual codes for "Hero" and "Homewrecker" into play and leaves the system to generate its own irresolvable meaning.

---

## 51 So about that shopping cart

I'm really not happy with my analysis of the shopping cart moment in [post 49](post49.html).

I said it was something like this guy's unwillingness to grow up or his rejection of responsibility. And I do think the song obviously doesn't just want us to let this guy off the hook when it comes to his daughter. The mom is definitely there in the doorway not buying even a little bit into her daughter's excitement to see her dad coming to pick her up. So that's there.

But it's not there in the shopping cart scene. The shopping cart is a moment of pleasure at work. It's something like a minimum-wage guy trying to steal a little time for himself while on the clock. So how does that fit in?

It's related to what I think is the biggest question about the song. Who is the "you" the song keeps talking to? Who is supposed to "let me go" and who is this "you" the guy refuses to belong to when he says, "I don't want to be your hero?"

The most painful and damning answer to that question is the daughter. But that can't be the conscious answer. That has to be some "real" answer the guy is refusing to acknowledge. That's the psychological argument I was trying to make in post 49.

But that's not the whole song. Is the "you" America? Is it the flag that shows up at different places? Is it war? (Any talk about heroes has to include hidden references to war, and what's a rodeo but a stand-in for war?) So he's not willing to be that kind of hero anymore? There's some of that, I think, but that's not it either. In [post 46](post46.html) I say it's the "grand larger-than-life hero" the song rejects. Maybe.

There are temptations to say something like "traditional masculinity" or "cultural American manhood" or something like that. But I don't think there's evidence in the song of rejecting that.

I don't have an answer right now. I'm going to keep working at it. I know it's connected to our Romantic intellectual heritage though. The hero for the Romantics was such a big deal. It's why they fell so hard for Napolean.

---

## 52 Ugh

I just watched Philip Nel's "How to resist the lure of AI." And ugh. Not because it's bad. It's the opposite. It's a sincere, passionate, and incredibly articulate defense of a certain way of seeing the world. It's so good at what it does that it feels like a final boss for this notebook. It's the perfect, complete statement of the thing I've been calling the ["Romantic trace."](post21.html)

Nel's whole argument is a masterclass in the worldview I sketched out in ["Romantic Evil."](post9.html) He gives nine reasons to resist AI, and every single one is a defense of the authentic, struggling, human soul against the machine. It's all here:

*   **Inauthenticity:** He contrasts the student's "distinct voice" with AI's "cheerful advertising copywriter" style. He wants the real you, not a simulation.
*   **Instrumentalism:** He calls AI a "plagiarism machine" built on the "theft of others work." It treats human creativity as a raw resource to be strip-mined.
*   **Profaned Communion:** His promise not to use AI to grade is the core of it. To do so would be to "outsource my job to a robot," to profane the sacred, personal exchange between teacher and student. It’s the pastor refusing to use a machine for a sermon because ["there's no one there."](post26.html)

He argues that "writing is a form of thinking," and that outsourcing thinking makes us dumber. He says he wants to see our "humanity," even if it's not "grammatically perfect." This is the Romantic ideal in its purest form. He's Walt Whitman on the Brooklyn Ferry, promising to be the living, breathing person on the other end of the educational line, pouring his authentic meaning into us. It’s a powerful and deeply moving vision of what education should be.

And I don't buy it.

The problem is that the entire argument is built on a foundation this blog has been questioning from the start. Nel’s critique is a moral one, aimed at AI’s lack of a soul, its inability to think or feel. But what if "thinking," at least the part that involves language, isn't what we think it is? What if it's not the expression of a unified inner self, but the operation of an impersonal system?

Nel says AI just "performs statistical pattern matching." Elan Barenholtz, the computational guy I've been reading, would say, "Exactly. And so do you." At least, the language part of you does. From this view, what Nel calls the "humanity" in writing is the result of a ["dance of symbols,"](post43.html) an "autonomous informational system" that got ["downloaded against your will."](post36.html)

This is the deep irony of the video. Nel delivers a passionate defense of the un-standardized, Socratic, human element of education while operating within the ultimate machine of standardization: the modern university. As I wrote in ["No wince in the syllabus,"](post29.html) the university system has been working for a long time to rationalize education, to turn it into a technique for producing a predictable result. AI isn't the alien invader coming to destroy the humanistic university; it's the logical fulfillment of the university we’ve already built.

In the end, Nel's video is a beautiful and heartfelt defense of what now survives only as a trace. He's guarding a sacred space—the authentic, human-to-human connection—that the technical systems we all live inside of have been systematically dismantling for centuries. The reason AI feels so threatening to this worldview is that it's the first time we've had a language machine where we can't even pretend there's a person on the other end. It strips away the illusion. It makes us confront the possibility that when it comes to language, maybe there never was a distinct presence in the language system to begin with, only patterned traces.